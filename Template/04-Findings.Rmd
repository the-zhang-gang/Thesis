---
output:
  bookdown::pdf_document2:
    template: templates/brief_template.tex
    citation_package: biblatex
  #bookdown::word_document2: default
  #bookdown::html_document2: default
documentclass: book
bibliography: references.bib
---

# Empirical Findings {#analysis}

\minitoc <!-- this will include a mini table of contents-->

## Density of the returns

```{r librariesfindings, include=F}
require(readxl)
require(xts)
require(PerformanceAnalytics)
require(kableExtra)
require(rugarch)
require(fitdistrplus)
require(fGarch)
require(tree)  # do we need this?
require(sgt)
require(devtools)
require(zoo)
require(parallel)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
# install_bitbucket("alexiosg/racd")
options(knitr.kable.NA = "")
remotes::install_github("R-Finance/xtsExtra")

data <- read_excel("data/datastream.xlsx",col_types = c("date", rep("numeric", 6)),skip = 2) #warnings are NA's
colnames(data) <- c("Date",gsub(pattern = " - PRICE INDEX", replacement='' , colnames(data)[2:7]))
Price_indices <- as.xts(data[,-1], order.by = data$Date)
Estoxx <- Price_indices[-1,1] #see if price index
R <- diff(Estoxx, log = TRUE, na.pad = FALSE)*100
require(readr)
```

### MLE distribution parameters

```{r mlesgt, eval=FALSE}
require(sgt)
require(graphics)
require(stats)
DistMLE <- function(R=R) {
  ### SGT
  X.data <- X ~ coredata(R)
  SGT_start <- list(mu=0,sigma=1, lambda = 0.5, p=2, q=8) # p = kappa, q = nu
  SGT_result <- sgt.mle(X.f = X.data, start = SGT_start)
  names(SGT_result$estimate) <- names(SGT_result$std.error) <-  c("alpha", "beta", "xi", "kappa", "eta")
  SGT_sumResult <- summary(SGT_result)
  SGT_AIC <- 2*length(SGT_result$estimate) - 2*SGT_sumResult$maximum
  SGT_pv <- 2* stats::pnorm(-abs(SGT_result$estimate/(SGT_result$std.error)))
  SGT_significance <- matrix(ncol = 5,nrow = 1)
  colnames(SGT_significance) <-  c("alpha", "beta", "xi", "kappa", "eta")
  for(i in 1:5){
  if(SGT_pv[i]>=0.10){
  SGT_significance[i] <-  ""
  }
  if(SGT_pv[i]<0.10){
  SGT_significance[i] <-  "*"  
  }
  if(SGT_pv[i]<0.05){
  SGT_significance[i] <-  "**"  
  }
  if(SGT_pv[i]<0.01){
  SGT_significance[i] <-  "***"  
  }
  }
  SGT_significance[is.na(SGT_significance)] <- ""

  ### SGED
  SGED_start <- list(mean=0,sd=1, nu = 2, xi = 1.5)
  SGED_result <- fitdist(data = as.vector(coredata(R)), distr = "sged", method = "mle", SGED_start)
  names(SGED_result$estimate) <- names(SGED_result$sd) <-  c("alpha", "beta", "kappa", "xi")
  SGED_sumResult <- summary(SGED_result)
  SGED_AIC <- 2*length(SGED_result$estimate-1) - 2*SGED_sumResult$loglik
  SGED_pv <- 2* stats::pnorm(-abs(SGED_result$estimate/(SGED_result$sd)))
  SGED_pv <- c(SGED_pv[1:2], SGED_pv[4], SGED_pv[3],NA)
  SGED_significance <- matrix(ncol =5,nrow = 1)
  colnames(SGED_significance) <-  c("alpha", "beta", "xi", "kappa", "eta")
  for(i in c(1:4)){
  if(SGED_pv[i]>=0.10){
  SGED_significance[i] <-  ""
  }
  if(SGED_pv[i]<0.10){
  SGED_significance[i] <-  "*"  
  }
  if(SGED_pv[i]<0.05){
  SGED_significance[i] <-  "**"  
  }
  if(SGED_pv[i]<0.01){
  SGED_significance[i] <-  "***"  
  }
  }
  SGED_significance[is.na(SGED_significance)] <- ""

  ### GED
  GED_start <- list(mean = 0, sd = 1, nu = 2)
  GED_result <- fitdist(data = as.vector(R),distr="ged", start = GED_start)
  names(GED_result$estimate) <- names(GED_result$sd) <-  c("alpha", "beta", "kappa")
  GED_sumResult <- summary(GED_result)
  GED_AIC <- 2*length(GED_result$estimate-2) - 2*GED_sumResult$loglik
  GED_pv <- 2* stats::pnorm(-abs(GED_sumResult$estimate/(GED_sumResult$sd)))
  GED_pv <- c(GED_pv[1:2], NA, GED_pv[3], NA)
  GED_significance <- matrix(ncol = 5,nrow = 1)
  colnames(GED_significance) <-  c("alpha", "beta", "xi", "kappa", "eta")
  for(i in c(1,2,4)){
  if(GED_pv[i]>=0.10){
  GED_significance[i] <-  ""
  }
  if(GED_pv[i]<0.10){
  GED_significance[i] <-  "*"  
  }
  if(GED_pv[i]<0.05){
  GED_significance[i] <-  "**"  
  }
    if(GED_pv[i]<0.01){
  GED_significance[i] <-  "***"  
  }
  }
  GED_significance[is.na(GED_significance)] <- ""

  ### ST (fitdist)
  ST_start <- list(mean=0,sd=1, nu = 5, xi=1.5)
  ST_result <- fitdistrplus::fitdist(data = as.vector(coredata(R)), distr = "sstd", method = "mle", ST_start)
  names(ST_result$estimate) <- names(ST_result$sd) <-  c("alpha", "beta", "eta","xi")
  ST_sumResult <- summary(ST_result)
  ST_sumResult$aic
  ST_pvalue <- 2*stats::pnorm(-abs(ST_sumResult$estimate/(ST_sumResult$sd)))
  ST_pvalue <-  c(ST_pvalue[1:2], ST_pvalue[4], NA, ST_pvalue[3])
  ST_significance <- matrix(ncol = 5,nrow = 1)
  colnames(ST_significance) <-  c("alpha", "beta", "xi", "kappa", "eta")
  for(i in c(1:3,5)){
  if(ST_pvalue[i]>=0.10){
  ST_significance[i] <-  ""
  }
  if(ST_pvalue[i]<0.10){
  ST_significance[i] <-  "*"  
  }
  if(ST_pvalue[i]<0.05){
  ST_significance[i] <-  "**"  
  }
    if(ST_pvalue[i]<0.01){
  ST_significance[i] <-  "***"  
  }
  }
  ST_significance[is.na(ST_significance)] <- ""

  ### T (fitdist)
  T_start <- list(mean = 0, sd = 1, nu = 5)
  T_result <- fitdistrplus::fitdist(data = as.vector(coredata(R)), distr = "std", method = "mle", T_start)
  names(T_result$estimate) <- names(T_result$sd) <-  c("alpha", "beta", "eta")
  T_sumResult <- summary(T_result)
  T_pvalues <-  2*stats::pnorm(-abs(T_result$estimate/(T_result$sd)))
  T_pvalues <-  c(T_pvalues[1:2], NA, NA, T_pvalues[3])
  T_significance <- matrix(ncol = 5,nrow = 1)
  colnames(T_significance) <-  c("alpha", "beta", "xi", "kappa", "eta")
  for(i in c(1,2,5)){
  if(T_pvalues[i]>=0.10){
  T_significance[i] <-  ""
  }
  if(T_pvalues[i]<0.10){
  T_significance[i] <-  "*"  
  }
  if(T_pvalues[i]<0.05){
  T_significance[i] <-  "**"  
  }
  if(T_pvalues[i]<0.01){
  T_significance[i] <-  "***"  
  }
  }
  T_significance[is.na(T_significance)] <- ""

  ### Normal (fitdist)
  Normal_start <- list(mean = 0, sd=1)
  Normal_result <- fitdist(as.vector(coredata(R)), "norm","mle", Normal_start)
  names(Normal_result$estimate) <- names(Normal_result$sd) <-  c("alpha", "beta")
  Normal_sumResult <- summary(Normal_result)
  Normal_AIC <- 2*length(Normal_result$estimate-3) - 2*Normal_sumResult$loglik
  Normal_pv <- 2*stats::pnorm(-abs(Normal_result$estimate/(Normal_result$sd)))
  Normal_significance <- matrix(ncol = 5,nrow = 1)
  colnames(Normal_significance) <-  c("alpha", "beta", "xi", "kappa", "eta")
  for(i in c(1:2)){
  if(Normal_pv[i]>=0.10){
  Normal_significance[i] <-  ""
  }
  if(Normal_pv[i]<0.10){
  Normal_significance[i] <-  "*"  
  }
  if(Normal_pv[i]<0.05){
  Normal_significance[i] <-  "**"  
  }
  if(Normal_pv[i]<0.01){
  Normal_significance[i] <-  "***"  
  }
  }
  Normal_significance[is.na(Normal_significance)] <- ""

#maximum likelihood estimates of unconditional distribution functions
Table2 <- matrix(nrow = 6, ncol = 7)
colnames(Table2) <- c("alpha","beta","xi","kappa","eta","LLH","AIC")
rownames(Table2) <- c("SGT","SGED","GED","ST","T","Normal")
# "alpha","beta","xi","kappa","nu","L","AIC"
Table2[1,1:5] <- SGT_result$estimate
Table2[1,6] <- SGT_result$maximum
Table2[1,7] <- SGT_AIC
# "alpha","beta","xi","kappa","nu","L","AIC"
Table2[2,1:2] <- SGED_result$estimate[1:2]
Table2[2,3] <- SGED_result$estimate[4] - 1
Table2[2,4] <- SGED_result$estimate[3]
Table2[2,5] <- Inf
Table2[2,6] <- SGED_result$loglik
Table2[2,7] <- SGT_AIC
# "alpha","beta","xi","kappa","nu","L","AIC"
Table2[3,1:2] <- GED_result$estimate[1:2]
Table2[3,3] <- 0
Table2[3,4] <- GED_result$estimate[3]
Table2[3,5] <- Inf
Table2[3,6] <- GED_result$loglik
Table2[3,7] <- GED_AIC
# "alpha","beta","xi","kappa","nu","L","AIC"
Table2[4,1:2] <- ST_result$estimate[1:2]
Table2[4,3] <- ST_result$estimate[4] - 1
Table2[4,4] <- 2
Table2[4,5] <- ST_result$estimate[3] # eta parameter is not exactly true here... See formula SGT package
Table2[4,6] <- ST_result$loglik
Table2[4,7] <- ST_result$aic
# "alpha","beta","xi","kappa","nu","L","AIC"
Table2[5,1:2] <- T_result$estimate[1:2]
Table2[5,3] <- 0
Table2[5,4] <- 2
Table2[5,5] <- T_result$estimate[3]/2 # eta parameters
Table2[5,6] <- T_result$loglik
Table2[5,7] <- T_result$aic

Table2[6,1:2] <- Normal_result$estimate[1:2]
Table2[6,3] <- 0
Table2[6,4] <- 2
Table2[6,5] <- Inf
Table2[6,6] <- Normal_result$loglik
Table2[6,7] <- Normal_result$aic

#adding SE
Table2_SE <- matrix(nrow = 12, ncol = 7)

Table2_SE <- as.data.frame(Table2_SE)
#coefficients placement
Table2_SE[1,] <- Table2[1,]
Table2_SE[3,] <- Table2[2,]
Table2_SE[5,] <- Table2[3,]
Table2_SE[7,] <- Table2[4,]
Table2_SE[9,] <- Table2[5,]
Table2_SE[11,] <- Table2[6,]
#fixing rownames, in a new column
colnames(Table2_SE) <- c("alpha","beta","xi","kappa","eta","L","AIC")
rownames(Table2_SE) <- 1:12
tablenames <- c("SGT","","SGED","","GED","","ST","","T","","Normal","")
Table2_SE <- cbind(tablenames,Table2_SE)
Table2_SE[c(1,3,5,7,9,11),-1] <- round(Table2_SE[c(1,3,5,7,9,11),-1], 3) #round

#SEs (basic)
# "alpha","beta","xi","kappa","eta","L","AIC"
Table2_SE[2,2:6] <- paste0("(",round(SGT_result$std.error, 3),")",SGT_significance)
# "alpha","beta","xi","kappa","eta","L","AIC"
#sd is correct, but the significance has to be fixed, same for GED, ST and T
Table2_SE[4,2:6] <- paste0("(",round(c(SGED_result$sd[1:2],SGED_result$sd[4], SGED_result$sd[3], NA),3),")", SGED_significance)
# "alpha","beta","xi","kappa","eta","L","AIC"
Table2_SE[6,2:6] <- paste0("(",round(c(GED_result$sd[1:2],NA,GED_result$sd[3],NA), 3),")",GED_significance)
# "alpha","beta","xi","kappa","eta","L","AIC"
Table2_SE[8,2:6] <- paste0("(",round(c(ST_result$sd[1:2],ST_result$sd[4],NA,ST_result$sd[3]),3),")",ST_significance)
# "alpha","beta","xi","kappa","eta","L","AIC"
Table2_SE[10,2:6] <- paste0("(",round(c(T_result$sd[-3],NA,NA,T_result$sd[3]),3),")",T_significance)
# "alpha","beta","xi","kappa","eta","L","AIC"
Table2_SE[12,2:6] <- paste0("(",round(c(Normal_result$sd, NA,NA,NA), 3),")",Normal_significance)


#Remove SE for limiting cases
# Table2_SE[6,4] <- NA
# Table2_SE[c(4,6),6] <- NA

totalresults <- list(table = Table2_SE, results = list(SGT = SGT_sumResult,SGED = SGED_sumResult, GED = GED_sumResult, ST = ST_sumResult, T = T_sumResult, Norm =Normal_sumResult))
return(totalresults)
}
```

```{r MLE tables for different series, include=FALSE, eval=FALSE, echo=FALSE}
R_dotcom <- window(R, start = "1987-01-01", end = "2001-12-31")
R_GFC <- window(R, start = "2002-01-01", end = "2009-03-31")
R_covid <- window(R, start = "2009-03-31")
length(R_dotcom); length(R_GFC); length(R_covid)

MLE_Full <- DistMLE(R)
MLE_dotcom <- DistMLE(R_dotcom)
MLE_GFC <- DistMLE(R_GFC)
MLE_covid <- DistMLE(R_covid)
```

In table \@ref(tab:MLEtable) we can see the estimated parameters of the unconditional distribution functions. They are presented for the Skewed Generalized T-distribution (SGT) and limiting cases thereof previously discussed. Additionally, maximum likelihood score and the Aikake Information Criterion (AIC) is reported to compare goodness of fit of the different distributions. We find that the SGT-distribution has the highest maximum likelihood score of all. All other distributions have relatively similar likelihood scores, though slightly lower and are therefore not the optimal distributions. However, when considering AIC it is a tie between SGT and SGED. This provides some indication that we have a valid case to test the suitability of different SGED-GARCH VaR models as an alternative for the SGT-GARCH VaR models. While sacrificing some goodness of fit, the SGED distribution has the advantage of requiring one less parameter, which could possibly result in less errors due to misspecification and easier implementation. For the SGT parameters the standard deviation and skewness are both significant at the 1% level. For the SGED parameters, the standard deviation and the skewness are both significant at respectively the 1% and 5% level. Both distributions are right-skewed. For both distributions the shape parameters are significant at the 1% level, though the $q$ parameter was not estimated as it is by design set to infinity due to the SGED being a limiting case of SGT.[^findings-1]

[^findings-1]: To check whether the relative ranking of distributions still holds in different periods, we have calculated the maximum likelihood score and AIC for three smaller periods: The period up to the dotcom collapse (1987-2001), up to the GFC (2002-2009) and up to the present Covid-crash (2009-2021). There is no qualitative difference in relative ranking with these subsamples. Results are reported in the appendix.

Additionally, for every distribution fitted with MLE, plots are generated to compare the theoretical distribution with the observed returns. We see that except for the normal distribution which is quite off, the theoretical distributions are close to the actual data, except that they are too peaked. This problem is the least present for the SGT distribution.

```{r table2prep, eval=FALSE}
# par(mfrow = c(3,2), mar = c(1,4,3,3))
Eurostoxx <- DistMLE(R)
table2 <- Eurostoxx$table
table2[table2 == "(NA)"] <- NA
colnames(table2) <- c("", "$\\alpha$","$\\beta$","$\\xi$","$\\kappa$","$\\eta$","$LLH$","AIC")
# table2 <-  data.frame(table2, check.names = F, fix.empty.names = FALSE)
```

```{r table2final,eval=FALSE, results='asis'}
kbl(table2,col.names= c("$\\theta$", "$\\alpha$","$\\beta$","$\\xi$","$\\kappa$","$\\eta$","$LLH$","AIC") ,caption = "Maximum likelihood estimates of unconditional distribution functions",
      label = 'MLEtable',"latex",
      booktabs = T,
      position = "h!",
      digits = 3,
    escape=F
      )%>%
  kable_classic(full_width = F)%>%
  footnote(general = "Table contains parameter estimates for SGT-distribution and some of its limiting \\\\\\\\ cases. The underlying data is the daily return series of the Euro Stoxx 50 \\\\\\\\ for the period between December 31. 1986 and April 27. 2021. Standard errors are reported between brackets. $LLH$ is the maximum log-likelihood value. *, ** and *** point out significance at 10%, 5% and 1% level.",threeparttable = T,footnote_as_chunk = F, escape=F, general_title = "Notes") %>%
  kable_styling(latex_options = "scale_down")
```

\newpage

## Constant higher moments

```{r garchcode, echo=FALSE}
distributions <- c("norm", "std", "sstd", "ged", "sged")
Models.garch <- c("sGARCH", "eGARCH","fGARCH.AVGARCH","fGARCH.NAGARCH", "gjrGARCH", "fGARCH.TGARCH", "iGARCH", "EWMA")
Models.garch.clean <-  toupper(gsub("fGARCH.", "", Models.garch)) # we use this for tables

for(i in 1:length(Models.garch)){
assign(paste0("garchspec.",Models.garch[i]),vector(mode = "list", length = length(distributions)))
assign(paste0("garchfit.",Models.garch[i]),vector(mode = "list", length = length(distributions)))
assign(paste0("stdret.",Models.garch[i]),vector(mode = "list", length = length(distributions)))
}

#.sGARCH--------------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.sGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "sGARCH", garchOrder = c(1,1), variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.sGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.sGARCH[[i]])
# Compute stdret using residuals()
stdret.sGARCH[[i]] <- rugarch::residuals(garchfit.sGARCH[[i]], standardize = TRUE)
}

#.eGARCH-------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.eGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "eGARCH", variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.eGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.eGARCH[[i]])
# Compute stdret using residuals()
stdret.eGARCH[[i]] <- rugarch::residuals(garchfit.eGARCH[[i]], standardize = TRUE)
}

#.fGARCH.NAGARCH------------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.fGARCH.NAGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "fGARCH", submodel = "NAGARCH", variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.fGARCH.NAGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.fGARCH.NAGARCH[[i]])
# Compute stdret using residuals()
stdret.fGARCH.NAGARCH[[i]] <- rugarch::residuals(garchfit.fGARCH.NAGARCH[[i]], standardize = TRUE)
}

#.fGARCH.AVGARCH------------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.fGARCH.AVGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "fGARCH", submodel = "AVGARCH", variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.fGARCH.AVGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.fGARCH.AVGARCH[[i]])
# Compute stdret using residuals()
stdret.fGARCH.AVGARCH[[i]] <- rugarch::residuals(garchfit.fGARCH.AVGARCH[[i]], standardize = TRUE)
}

#.gjrGARCH------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.gjrGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "gjrGARCH", variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.gjrGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.gjrGARCH[[i]])
# Compute stdret using residuals()
stdret.gjrGARCH[[i]] <- rugarch::residuals(garchfit.gjrGARCH[[i]], standardize = TRUE)
}

#fGARCH.TGARCH-------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.fGARCH.TGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "fGARCH", submodel = "TGARCH", variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.fGARCH.TGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.fGARCH.TGARCH[[i]])
# Compute stdret using residuals()
stdret.fGARCH.TGARCH[[i]] <- rugarch::residuals(garchfit.fGARCH.TGARCH[[i]], standardize = TRUE)
}

#.iGARCH--------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.iGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "iGARCH", variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.iGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.iGARCH[[i]])
# Compute stdret using residuals()
stdret.iGARCH[[i]] <- rugarch::residuals(garchfit.iGARCH[[i]], standardize = TRUE)
}

#.EWMA-----------------
# we need EWMA
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.EWMA[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "iGARCH", variance.targeting = F),
                     distribution.model = distributions[i], fixed.pars = list(omega=0))
# Estimate the model
garchfit.EWMA[[i]] <- ugarchfit(data = R, spec = garchspec.EWMA[[i]])
# Compute stdret using residuals()
stdret.EWMA[[i]] <- rugarch::residuals(garchfit.EWMA[[i]], standardize = TRUE)
}


#  make the histogram
#
# chart.Histogram(stdret.iGARCH[[1]], methods = c("add.normal","add.density" ),
#                 colorset = c("gray","red","blue"))
```

```{r table3prep, echo=FALSE}
require(plyr)
require(dplyr)
require(stringr)
Table.GARCH.function <- function(GARCHfit.object = garchfit.eGARCH){
#Making objects to fill   
list.table.3.tmp <- vector(mode = "list", length = length(distributions)*2)
list.table.3 <- vector(mode = "list", length = length(distributions))
names(list.table.3) <- distributions
ref.distr <- seq(from = 1, to = length(distributions)*2, by = 2)
#Retriving all the data from the original lists
for(i in 1:length(distributions)){
    list.table.3.tmp[[ref.distr[i]]] <- GARCHfit.object[[i]]@fit$coef
    list.table.3.tmp[[ref.distr[i]+1]] <- GARCHfit.object[[i]]@fit$tval
}
#From list of vectors of different lengths to list of matrixes with empty spaces filled with NAs
for(i in 1:length(distributions)){
  list.table.3[[i]] <- cbind(list.table.3.tmp[[ref.distr[i]]], list.table.3.tmp[[ref.distr[i]+1]][match(names(list.table.3.tmp[[ref.distr[i]]]), names(list.table.3.tmp[[ref.distr[i]+1]]))])
}
#Function to rearrange the list from a list of matrices to list of vectors
list.restructure <- function(object = list.table.3){
  len.table <- length(object)
  len.inside.list <- rep(NA, len.table)
  for(i in 1:len.table){len.inside.list[i] <- nrow(object[[i]])}
  adj.list <- vector(mode = "list", length = len.table)
  ref.list <- vector(mode = "list", length = len.table)
  names.list <- vector(mode = "list", length = len.table)
  for(i in 1:len.table){ref.list[[i]] <- seq(from = 1, to = len.inside.list[i]*2, by = 2)}
  for(i in 1:len.table){adj.list[[i]] <- names.list[[i]] <- rep(NA, len.inside.list[i]*2)}
  for(i in 1:len.table){
      adj.list[[i]][ref.list[[i]]] <- round(object[[i]][,1],3)
      adj.list[[i]][ref.list[[i]]+1] <- paste0("(", round(object[[i]][,2],3),")")
  }
  for(i in 1:len.table){
    names.list[[i]][ref.list[[i]]] <- rownames(object[[i]])
    names.list[[i]][ref.list[[i]]+1] <- paste0("p-val ",rownames(object[[i]]))
    #names.list[[i]][ref.list[[i]]+1] <- ""
    }
  names(adj.list) <- distributions
  for(i in 1:len.table){names(adj.list[[i]]) <- names.list[[i]]}
  return(adj.list)
}
#Unlisting and removing NAs
adj.list <- list.restructure(object = list.table.3)
table.3.matrix <- matrix(unlist(lapply(adj.list, `length<-`, max(lengths(adj.list)))),ncol = length(distributions),nrow = max(lengths(adj.list)), byrow = F)
colnames(table.3.matrix) <- names(adj.list)
table.3.matrix[is.na(table.3.matrix)] <- ""
table.3.matrix[table.3.matrix=="(NA)"] <- ""
#Adjustments for std & ged distributions
table.3.matrix[c(length(table.3.matrix[,2])-1,length(table.3.matrix[,2])),2] <- tail(table.3.matrix[table.3.matrix[,2]!="",2],2)
table.3.matrix[c(length(table.3.matrix[,2])-3,length(table.3.matrix[,2])-2),2] <- ""
table.3.matrix[c(length(table.3.matrix[,4])-1,length(table.3.matrix[,4])),4] <- tail(table.3.matrix[table.3.matrix[,4]!="",4],2)
table.3.matrix[c(length(table.3.matrix[,4])-3,length(table.3.matrix[,4])-2),4] <- ""
#Log-Likelyhoods
LLH <- rep(NA, length(distributions))
for(i in 1:length(distributions)){LLH[i] <- GARCHfit.object[[i]]@fit$LLH}
names.table.3 <- revalue(names(adj.list[[3]]), c("mu"="$\\alpha_0$", "ar1"="$\\alpha_1$", "omega"= "$\\beta_0$", "alpha1"="$\\beta_1$", "beta1"="$\\beta_2$", "gamma1"="$\\gamma$", "skew"="$\\xi$", "shape"="$\\kappa$", "eta11"="$rot$", "eta21"="$shift$"), warn_missing = F)
kappa.object <- cbind(matrix(data = "", nrow = 2, ncol = 3) ,table.3.matrix[(nrow(table.3.matrix)-1):(nrow(table.3.matrix)),4:5])
eta <- cbind(table.3.matrix[(nrow(table.3.matrix)-1):(nrow(table.3.matrix)),1:3], matrix(data = "", nrow = 2, ncol = 2) )
table.3.matrix[(nrow(table.3.matrix)-1):(nrow(table.3.matrix)),] <- kappa.object
table.3.matrix <- rbind(table.3.matrix, eta, round(LLH,3))
table.3.matrix <- cbind(c(names.table.3,"$\\eta$","p-val eta","$LLH$"), table.3.matrix)
table.3.matrix <- as.data.frame(table.3.matrix, row.names = c(names.table.3,"$\\eta$","","LLH"))
return(table.3.matrix)
}

#PARTIAL RESULTS

Table.3.iGARCH <- Table.GARCH.function(GARCHfit.object = garchfit.iGARCH)
Table.3.eGARCH <- Table.GARCH.function(GARCHfit.object = garchfit.eGARCH)
Table.3.gjrGARCH <- Table.GARCH.function(GARCHfit.object = garchfit.gjrGARCH)
Table.3.sGARCH <- Table.GARCH.function(GARCHfit.object = garchfit.sGARCH)
Table.3.EWMA <- Table.GARCH.function(GARCHfit.object = garchfit.EWMA)
Table.3.fGARCH.AVGARCH <- Table.GARCH.function(GARCHfit.object = garchfit.fGARCH.AVGARCH)
Table.3.fGARCH.NAGARCH <- Table.GARCH.function(GARCHfit.object = garchfit.fGARCH.NAGARCH)
Table.3.fGARCH.TGARCH <- Table.GARCH.function(GARCHfit.object = garchfit.fGARCH.TGARCH)

Table.3.function <- function(distribution = "sstd"){
ref <- which(names(Table.3.eGARCH)==distribution)#Reference column
#Taking all the relevant values
AVGARCH <- Table.3.fGARCH.AVGARCH[,c(1,ref)]
iGARCH <- Table.3.iGARCH[,c(1,ref)]
eGARCH <- Table.3.eGARCH[,c(1,ref)]
sGARCH <- Table.3.sGARCH[,c(1,ref)]
gjrGARCH <- Table.3.gjrGARCH[,c(1,ref)]
EWMA <- Table.3.EWMA[,c(1,ref)]
NAGARCH <- Table.3.fGARCH.NAGARCH[,c(1,ref)]
TGARCH <- Table.3.fGARCH.TGARCH[,c(1,ref)]
#Assigning the right names to columns
colnames(AVGARCH)[-1] <- rep("AVGARCH", length(colnames(AVGARCH)[-1]))
colnames(iGARCH)[-1] <- rep("iGARCH", length(colnames(iGARCH)[-1]))
colnames(eGARCH)[-1] <- rep("eGARCH", length(colnames(eGARCH)[-1]))
colnames(sGARCH)[-1] <- rep("sGARCH", length(colnames(sGARCH)[-1]))
colnames(gjrGARCH)[-1] <- rep("gjrGARCH", length(colnames(gjrGARCH)[-1]))
colnames(EWMA)[-1] <- rep("EWMA", length(colnames(EWMA)[-1]))
colnames(NAGARCH)[-1] <- rep("NAGARCH", length(colnames(NAGARCH)[-1]))
colnames(TGARCH)[-1] <- rep("TGARCH", length(colnames(TGARCH)[-1]))
#Binding all the columns & cleaning & ordering data
Table3 <- full_join(full_join(full_join(full_join(full_join(full_join(full_join(sGARCH, iGARCH),eGARCH),gjrGARCH),EWMA),NAGARCH),TGARCH),AVGARCH)
Table3[is.na(Table3)] <- ""
Table3 <- rbind(Table3[Table3[,1]!="$LLH$",], Table3[Table3[,1]=="$LLH$",])
Table3[substr(Table3[,1],1,5)=="p-val",1] <- ""
colnames(Table3) <- c("", colnames(Table3)[-1])
return(Table3)
}

Table.3 <- vector(mode = "list", length = length(distributions))
names(Table.3) <- c("Norm", "T", "ST", "GED", "SGED")
for(i in 1:length(distributions)){
  Table.3[[i]] <- suppressMessages(Table.3.function(distribution = distributions[i]))
}
#Kabling

fn1.3 <- sprintf(paste0('This table shows the maximum likelihood estimates of various ST-GARCH \\\\\\\\ models. The daily returns used on the ',str_to_title(gsub(pattern = '\\.', replacement=' ',colnames(R)))," Price index cover the  \\\\\\\\ periodfrom ",gsub(" UTC", "",format(min(index(R)), '%d %B, %Y'))," to ",gsub(" UTC", "",format(max(index(R)),'%d %B, %Y')), " (", nrow(R)," observations)."))
fn2.3 <- sprintf("The mean process is modeled as follows: $R_t= \\\\alpha_0+ \\\\alpha_1 \\\\times R_{t-1}+ \\\\varepsilon_t \\\\\\\\$ Where, in the %s GARCH models estimated, $\\\\gamma$ is the asymmetry in volatility \\\\\\\\, $\\\\xi, \\\\kappa$ and $\\\\eta$ are constant and $t$ statistics are displayed in parenthesis. \\\\\\\\$LLH$ is the maximized log likelihood value.", ncol(Table.3$ST)-1)
```

\noindent \@ref(tab:Table3) presents the maximum likelihood estimates for `r ncol(Table.3$ST)-1` symmetric and asymmetric GARCH models based on the ST distribution with constant skewness and kurtosis parameters ($t$ values are presented in parenthesis). The parameters in the conditional mean equations ($\alpha_0$) are all statistically significant with $t$ values from `r min(as.numeric(str_remove_all(Table.3$ST[2,-1], "[()]")))` to `r max(as.numeric(str_remove_all(Table.3$ST[2,-1], "[()]")))`. The AR(1) coefficient, $\alpha_1$, has parameters going from `r min(as.numeric(Table.3$ST[3,-1]))` to `r max(as.numeric(Table.3$ST[3,-1]))` with $t$ values ranging from `r min(as.numeric(str_remove_all(Table.3$ST[4,-1], "[()]")))` to `r max(as.numeric(str_remove_all(Table.3$ST[4,-1], "[()]")))` not suggesting a high significance and indicating slight negative autocorrelation. The GARCH parameters in the conditional variance equations ($\beta_0$) are generally statistically significant with $t$ values ranging from `r min(as.numeric(str_remove_all(Table.3$ST[6,-1], "[()]")), na.rm = TRUE)` to `r max(as.numeric(str_remove_all(Table.3$ST[6,-1], "[()]")), na.rm = TRUE)`. The results of $\beta_1$ and $\beta_2$ show the presence of significant time-variation in the conditional volatility of the Euro Stoxx 50 Price Index daily returns, in fact, the sum of $\beta_1$ and $\beta_2$ for the GARCH parameters is close to one (from `r min(as.numeric(str_remove_all(as.numeric(Table.3$ST[7,-1])+as.numeric(Table.3$ST[9,-1]), "[()]")), na.rm = TRUE)` to `r max(as.numeric(str_remove_all(as.numeric(Table.3$ST[7,-1])+as.numeric(Table.3$ST[9,-1]), "[()]")), na.rm = TRUE)`), suggesting the presence of persistence in the volatility of the returns. The parameter $\xi$ is highly significant for all the `r ncol(Table.3$ST)-1` models tested with values ranging from `r min(as.numeric(str_remove_all(Table.3$ST[11,-1], "[()]")), na.rm = TRUE)` to `r max(as.numeric(str_remove_all(Table.3$ST[11,-1], "[()]")), na.rm = TRUE)` confirming the presence of Skewness in the returns. The shape parameter $\eta$, which, in our case, measures the number of degrees of freedom, determining the tail behavior, is significant for all the models and ranges between `r min(as.numeric(str_remove_all(Table.3$ST[15,-1], "[()]")), na.rm = TRUE)` and `r max(as.numeric(str_remove_all(Table.3$ST[15,-1], "[()]")), na.rm = TRUE)`. The parameter $\gamma$, which is present only for eGARCH and gjrGARCH is significant and with values around `r round(mean(as.numeric(str_remove_all(Table.3$ST[17,-1], "[()]")), na.rm = TRUE),2)`. The absolute value function in fGARCH models (NAGARCH, TGARCH and AVGARCH) is subject to the $shift$ and the $rot$ parameters whose values are always positive and statistically significant. According to the log likelihood values ($LLH$), displayed in \@ref(tab:Table3), the model with the highest value is `r colnames(Table.3$ST[,-1])[which.max(as.numeric(str_remove_all(Table.3$ST[23,-1], "[()]")))]` while, excluding the non-standard GARCH models from the analysis, the model that performs best is `r colnames(Table.3$ST[,-c(1,7,8,9)])[which.max(as.numeric(str_remove_all(Table.3$ST[23,-c(1,7,8,9)], "[()]")))]`.

```{r table3final, echo=F, results='asis'}
kbl(Table.3$ST[-c(13,14),], col.names = toupper(colnames(Table.3$ST)),caption = "Maximum likelihood estimates of the ST-GARCH models with constant skewness and kurtosis parameters","latex",
      label = 'Table3',
      booktabs = T, row.names = F, escape = F )%>%
  #kable_classic(full_width = F)%>%
  footnote(general = c(fn1.3,fn2.3),threeparttable = T,footnote_as_chunk = F, escape=F, general_title = "Notes")%>%
  kable_styling(latex_options = "scale_down")
```

\newpage

As you can see in table \@ref(tab:aicTable) the AIC for the skewed student's t-distribution (ST) is the best from all the models. As also shown in appendix part \@ref(goodness-of-fit). The best in all distributions of the GARCH models seems to be the NAGARCH model, but we do not want to overfit our models because of an in-sample estimation. That is why a parsimonous model like the EGARCH (which has the highest maximum likelihood for the standard GARCH models that are considered), but also the model AVGARCH will be examined using the ST distribution while it has the second-best (lowest) AIC.

```{r aictableprep, echo=F}
aic_sGARCH <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_sGARCH[i] = infocriteria(garchfit.sGARCH[[i]])[1]
}

aic_iGARCH <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_iGARCH[i] = infocriteria(garchfit.iGARCH[[i]])[1]
}

aic_EWMA <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_EWMA[i] = infocriteria(garchfit.EWMA[[i]])[1]
}

aic_eGARCH <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_eGARCH[i] = infocriteria(garchfit.eGARCH[[i]])[1]
}

aic_gjrGARCH <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_gjrGARCH[i] = infocriteria(garchfit.gjrGARCH[[i]])[1]
}

aic_naGARCH <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_naGARCH[i] = infocriteria(garchfit.fGARCH.NAGARCH[[i]])[1]
}

aic_tGARCH <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_tGARCH[i] = infocriteria(garchfit.fGARCH.TGARCH[[i]])[1]
}

aic_avgarch <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_avgarch[i] = infocriteria(garchfit.fGARCH.AVGARCH[[i]])[1]
}

aics <- matrix(ncol=length(Models.garch), nrow = length(distributions))
rownames(aics) <- distributions
colnames(aics) <- Models.garch.clean[c(1,7,8,2,5,4,6,3)]
aics[,1] <- aic_sGARCH
aics[,2] <- aic_iGARCH
aics[,3] <- aic_EWMA
aics[,4] <- aic_eGARCH
aics[,5] <- aic_gjrGARCH
aics[,6] <- aic_naGARCH
aics[,7] <- aic_tGARCH
aics[,8] <- aic_avgarch

tableAIC <- as.data.frame(round(aics,4))
# try 2
tableAIC$SGARCH = cell_spec(tableAIC$SGARCH, color = ifelse(tableAIC$SGARCH==min(tableAIC$SGARCH), "green", "black"))

# for ourselves: quick conditional formatting
#require(condformat)
# cf <-  condformat(tableAIC) %>%
#   rule_fill_discrete(SGARCH,expression =SGARCH==min(SGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(IGARCH,expression =IGARCH==min(IGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(EWMA,expression =EWMA==min(EWMA), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(EGARCH,expression =EGARCH==min(EGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(GJRGARCH,expression =GJRGARCH==min(GJRGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(NAGARCH,expression =NAGARCH==min(NAGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen"))  %>%
#   rule_fill_discrete(TGARCH,expression =TGARCH==min(TGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(AVGARCH,expression =AVGARCH==min(AVGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen"))
```

```{r aictablelatex, echo=F, results='asis'}
aics %>% kbl(caption = "Model selection according to AIC",format = "latex",
      label = 'aicTable',
      booktabs = T,
      position = "h!",
      digits = 3 )%>%
  kable_classic(full_width = F)%>%
  footnote(general = "Notes",number="This table shows the AIC value for the respective model",threeparttable = T,footnote_as_chunk = F, escape=F, general_title = "") %>%
  kable_styling(latex_options = "scale_down") %>% landscape()
```

```{=tex}
\clearpage
\newpage
```
### Value-at-risk

As already mentioned 2 candidate models seem to be very appropriate. This includes the EGARCH and the NAGARCH So to check if they perform well out-of-sample we conduct a backtest by using a rolling forecasting technique. A simple graph is shown in figure \@ref(fig:figVaRinsample) for the EGARCH-ST model. It seems that the VaR model for $\alpha=0.05$ underestimates the downside events, while the VaR model for $\alpha=0.01$ captures more of the downside events.

```{r figVaRinsample, fig.cap="Value-at-Risk (in-sample) for the EGARCH-ST model", fig.align='center', fig.pos = 'h', out.width='60%', echo=FALSE}
par(mfrow = c(2,1))
par(mar = c(2.1, 3.1, 1.1, 3.1))
Conditional.variance <- sigma(garchfit.eGARCH[[3]])
Conditional.mean <- fitted(garchfit.eGARCH[[3]])
n <- garchfit.eGARCH[[3]]@fit$coef["shape"]
VaR05 <- as.numeric(Conditional.mean + Conditional.variance*qdist("sstd",p=0.05,
shape = coef(garchfit.eGARCH[[3]])["shape"],skew  = coef(garchfit.eGARCH[[3]])["skew"]))
plot(as.matrix(R), type = "l" , xlab = "" ,
ylab = "95% VaR value", col = "darkgray"); lines(VaR05,col = adjustcolor("red",alpha.f=0.5)); legend ("topleft", bty = "n", lty = c (1,1) , col = c("darkgrey", adjustcolor("red" ,alpha.f =0.5)) ,legend = c(expression(R[t]), expression(VaR[0.05][","][t])))

VaR01 <- as.numeric(Conditional.mean + Conditional.variance*qdist("sstd",p=0.01,
shape = coef(garchfit.eGARCH[[3]])["shape"],skew  = coef(garchfit.eGARCH[[3]])["skew"]))
plot(as.matrix(R), type = "l" , xlab = "T" ,
ylab = "99% VaR value", col = "darkgray"); lines(VaR01, col = adjustcolor("green",alpha.f=0.5)); legend ("topleft", bty = "n", lty = c (1,1) , col = c("darkgrey", adjustcolor("green" ,alpha.f =0.5)) ,legend = c(expression(R[t]), expression(VaR[0.01][","][t])))
```

Let us examine this further using a rolling window approach whilst forecasting 1-day ahead results with re-estimating parameters every year.

[\|**Note for prof. Annaert: choices**: \
-- n.start = 2500 ==\> sample = 2500 observations to forecast the next, \
-- refit.every = 252 (trading days in a year) ==\> so recompute the parameters every year, \
-- solver = hybrid using cluster = 10 to run on 10 cores to speed up the process of estimation of the roll object (took 5-10 minutes per backtest with some solvers, now with parallel package...)\
-- forecast.length = 1 ==\> length of total forecast for which out of sample data from dataset will be used for testing \|]{highlight="pink"}

\newpage

Figure \@ref(fig:figbacktest) shows that choosing an appropriate forecast period is important (with here the Eurobond crisis, the Brexit and Covid-crisis), so in order to avoid a look-ahead bias this rolling window approach was used. \newpage

```{r figbacktest, fig.cap = "Selected period to start forecast from",out.width='70%', fig.align='center', echo=FALSE}
par(mfrow = c(1,1), mar = c(2, 2, 2, 2))
xtsExtra::plot.xts(Estoxx, col = 'steelblue', screens = 1, blocks = list(start.time = paste(head(tail(index(Estoxx),2500), 1)), end.time = paste(index(tail(Estoxx, 1))), col = 'grey90'), main = 'Euro Stoxx 50', minor.ticks = FALSE)
```

```{r garchroll, echo = FALSE}
# VaR garchroll forecasting and backtesting----
# x = garchspec.eGARCH[[i]]
roll <- function(x) { 
  cl = makePSOCKcluster(10)
  result = ugarchroll(x,data = R,n.ahead = 1,n.start = 2500,forecast.length=1,refit.every = 252,solver = "hybrid",refit.window="moving",calculate.VaR=TRUE,VaR.alpha=0.01, cluster = cl, keep.coef=TRUE)
  stopCluster(cl)
  return(result)
}
# Enjo Timing = first hash
egarch.normback <- roll(garchspec.eGARCH[[1]]) #19.66 sec
egarch.stdback <- roll(garchspec.eGARCH[[2]])  #22.68 sec
egarch.sstdback <- roll(garchspec.eGARCH[[3]]) #24.02 sec
egarch.gedback <- roll(garchspec.eGARCH[[4]])  #20.54 sec
egarch.sgedback <- roll(garchspec.eGARCH[[5]]) #30.70 sec

gjrgarch.normback <- roll(garchspec.gjrGARCH[[1]]) #14.23 sec
gjrgarch.stdback <- roll(garchspec.gjrGARCH[[2]])  #19.36 sec
gjrgarch.sstdback <- roll(garchspec.gjrGARCH[[3]]) #24.75 sec
gjrgarch.gedback <- roll(garchspec.gjrGARCH[[4]])  #21.13 sec
gjrgarch.sgedback <- roll(garchspec.gjrGARCH[[5]]) #30.24 sec

nagarch.normback <- roll(garchspec.fGARCH.NAGARCH[[1]]) #14.88 sec
nagarch.stdback <- roll(garchspec.fGARCH.NAGARCH[[2]])  #20.31 sec
nagarch.sstdback <- roll(garchspec.fGARCH.NAGARCH[[3]]) #27.25 sec
nagarch.gedback <- roll(garchspec.fGARCH.NAGARCH[[4]])  #22.39 sec
nagarch.sgedback <- roll(garchspec.fGARCH.NAGARCH[[5]]) #34.98 sec

tgarch.normback <- roll(garchspec.fGARCH.TGARCH[[1]]) #15.48 sec
tgarch.stdback <- roll(garchspec.fGARCH.TGARCH[[2]])  #19.32 sec
tgarch.sstdback <- roll(garchspec.fGARCH.TGARCH[[3]]) #26.27 sec
tgarch.gedback <- roll(garchspec.fGARCH.TGARCH[[4]])  #20.26 sec
tgarch.sgedback <- roll(garchspec.fGARCH.TGARCH[[5]]) #29.29 sec

avgarch.normback <- roll(garchspec.fGARCH.AVGARCH[[1]]) #20.65 sec
avgarch.stdback <- roll(garchspec.fGARCH.AVGARCH[[2]])  #35.63 sec
avgarch.sstdback <- roll(garchspec.fGARCH.AVGARCH[[3]]) #52.54 sec
avgarch.gedback <- roll(garchspec.fGARCH.AVGARCH[[4]])  #42.59 sec
avgarch.sgedback <- roll(garchspec.fGARCH.AVGARCH[[5]]) #1.03 min

q1 = q5 = px = matrix(NA, ncol = 1, nrow = 6453)
q1[, 1] = as.numeric(apply(egarch.normback@forecast$density, 1, function(x) qdist("norm", 0.01, mu = x['Mu'], sigma = x['Sigma'], skew = x['Skew'], shape = x['Shape'])))
q5[, 1] = as.numeric(apply(egarch.normback@forecast$density, 1, function(x) qdist("norm", 0.05, mu = x['Mu'], sigma = x['Sigma'], skew = x['Skew'], shape = x['Shape'])))
VaR1cc1 = apply(q1, 2, function(x) VaRTest(0.01, actual = egarch.normback@forecast$VaR[, 'realized'], VaR = x))
VaR5cc1 = apply(q5, 2, function(x) VaRTest(0.05, actual = egarch.normback@forecast$VaR[, 'realized'], VaR = x))
```

As you can see in figure \@ref(figurebacktests2) the EGARCH with a normal distribution seems to capture the extreme events a bit less compared with the skewed t-distribution. But let us formally test this.

```{r figurebacktests2,fig.cap = "Comparison between VaR-EGARCH-ST and VaR-NAGARCH-N", fig.align='center', echo=FALS, echo=FALSE, out.width="70%"}
# EGARCH with sstd vs NAGARCH with sstd
par(mfrow = c(2,1), mar = c(2.5,2.5,1.5,2.5))
# EGARCH with SSTD
plot(egarch.sstdback,which=4,VaR.alpha=0.01)
legend("topright",bty="n",legend= bquote(~ alpha == "0.01"))
title(main = "EGARCH-ST")

# NAGARCH with SSTD
plot(egarch.normback,which=4,Var.alpha=0.01)
legend("topright",bty="n",legend= bquote(~ alpha == "0.01"))
title(main = "EGARCH-N")
```

```{r gaspackagetests, include=F, echo=F}
require(GAS)
getVaR <- function(x) {
  VaRresult <- as.data.frame(x,which="VaR")$`alpha(1%)`
}
VaR.norm.egarch <- getVaR(egarch.normback)
VaR.std.egarch <- getVaR(egarch.stdback)
VaR.ged.egarch <- getVaR(egarch.gedback)
VaR.sstd.egarch <- getVaR(egarch.sstdback)
VaR.sged.egarch <- getVaR(egarch.sgedback)

VaR.norm.gjrgarch <- getVaR(gjrgarch.normback)
VaR.std.gjrgarch <- getVaR(gjrgarch.stdback)
VaR.ged.gjrgarch <- getVaR(gjrgarch.gedback)
VaR.sstd.gjrgarch <- getVaR(gjrgarch.sstdback)
VaR.sged.gjrgarch <- getVaR(gjrgarch.sgedback)

VaR.norm.tgarch <- getVaR(tgarch.normback)
VaR.std.tgarch <- getVaR(tgarch.stdback)
VaR.ged.tgarch <- getVaR(tgarch.gedback)
VaR.sstd.tgarch <- getVaR(tgarch.sstdback)
VaR.sged.tgarch <- getVaR(tgarch.sgedback)

VaR.norm.nagarch <- getVaR(nagarch.normback)
VaR.std.nagarch <- getVaR(nagarch.stdback)
VaR.ged.nagarch <- getVaR(nagarch.gedback)
VaR.sstd.nagarch <- getVaR(nagarch.sstdback)
VaR.sged.nagarch <- getVaR(nagarch.sgedback)

VaR.norm.avgarch <- getVaR(avgarch.normback)
VaR.std.avgarch <- getVaR(avgarch.stdback)
VaR.ged.avgarch <- getVaR(avgarch.gedback)
VaR.sstd.avgarch <- getVaR(avgarch.sstdback)
VaR.sged.avgarch <- getVaR(avgarch.sgedback)

gettests <- function(x) { 
  # modify this according to your needs
  uc <- BacktestVaR(R[2501:nrow(R)],x,0.01, 5)$LRuc
  cc <- BacktestVaR(R[2501:nrow(R)],x,0.01, 5)$LRcc
  ae <- BacktestVaR(R[2501:nrow(R)],x,0.01, 5)$AE
  dq <- BacktestVaR(R[2501:nrow(R)],x,0.01, 5)$DQ
  return(list = list(ae = ae, uc = uc, cc = cc, dq = dq))
}
```

```{r ES_Test}
ESTesting <- function(garch.back, var, dist){
  
  roll <- as.data.frame(garch.back, which = "density",)
  
  
  f <- function(x, skew, shape) qdist(dist, p = x, mu = 0, sigma = 1, skew = skew, shape = shape)
  
  #VaR in same fashion as ES below, and gives the same VaR as previously found so it is redundant.
  # VaR <- roll[,'Mu'] + qdist(dist, 0.01, mu = 0, sigma =1, skew = roll[,'Skew'], shape = roll[,'Shape']) * roll[,'Sigma']
  
  
  ES <- roll['Mu'] + roll['Sigma']*apply(roll, 1, function(x)
    integrate(f,0,0.01, skew = x['Skew'], shape = x['Shape'])$value/0.01)
  names(ES) <- "ES"
  
  ESTest_object <- ESTest(0.01, R[-c(1:2500),], ES[,1], var, conf.level = 0.99, boot = T)
  
  # length(R)
  # nrow(ES)
  # length(VaR.sstd.egarch)
  
  AE_ES <- as.numeric(ESTest_object[2])/as.numeric(ESTest_object[1])
  AE_ES.p <- ESTest_object[4] #bootstrapped p-value
  
  
  return(list(ES,AE_ES,AE_ES.p))
}


#ES for egarch

e_sged_ES <- ESTesting(egarch.sgedback, VaR.sged.egarch, "sged")
e_sged_AE_ES <- e_sged_ES[2]
e_sged_AE_p <- e_sged_ES[[3]] 

e_ged_ES <- ESTesting(egarch.gedback, VaR.ged.egarch, "ged")
e_ged_AE_ES <- e_ged_ES[2]
e_ged_AE_p <- e_ged_ES[[3]] 

e_sstd_ES <- ESTesting(egarch.sstdback, VaR.sstd.egarch, "sstd")
e_sstd_AE_ES <- e_sstd_ES[2]
e_sstd_AE_p <- e_sstd_ES[[3]] 

e_std_ES <- ESTesting(egarch.sstdback, VaR.std.egarch, "std")
e_std_AE_ES <- e_std_ES[2]
e_std_AE_p <- e_std_ES[[3]] 

e_norm_ES <- ESTesting(egarch.normback, VaR.norm.egarch, "norm")
e_norm_AE_ES <- e_norm_ES[2]
e_norm_AE_p <- e_norm_ES[[3]]

#ES for gjrgarch

gjr_sged_ES <- ESTesting(gjrgarch.sgedback, VaR.sged.gjrgarch,"sged")
gjr_sged_AE_ES <- gjr_sged_ES[2]
gjr_sged_AE_p <- gjr_sged_ES[[3]] 

gjr_ged_ES <- ESTesting(gjrgarch.gedback, VaR.ged.gjrgarch,"ged")
gjr_ged_AE_ES <- gjr_ged_ES[2]
gjr_ged_AE_p <- gjr_ged_ES[[3]] 

gjr_sstd_ES <- ESTesting(gjrgarch.sstdback, VaR.sstd.gjrgarch,"sstd")
gjr_sstd_AE_ES <- gjr_sstd_ES[2]
gjr_sstd_AE_p <- gjr_sstd_ES[[3]] 

gjr_std_ES <- ESTesting(gjrgarch.sstdback,VaR.std.gjrgarch, "std")
gjr_std_AE_ES <- gjr_std_ES[2]
gjr_std_AE_p <- gjr_std_ES[[3]] 

gjr_norm_ES <- ESTesting(gjrgarch.normback, VaR.norm.gjrgarch,"norm")
gjr_norm_AE_ES <- gjr_norm_ES[2]
gjr_norm_AE_p <- gjr_norm_ES[[3]]

#ES for tgarch

t_sged_ES <- ESTesting(tgarch.sgedback, VaR.sged.tgarch,"sged")
t_sged_AE_ES <- t_sged_ES[2]
t_sged_AE_p <- t_sged_ES[[3]] 

t_ged_ES <- ESTesting(tgarch.gedback, VaR.ged.tgarch,"ged")
t_ged_AE_ES <- t_ged_ES[2]
t_ged_AE_p <- t_ged_ES[[3]] 

t_sstd_ES <- ESTesting(tgarch.sstdback, VaR.sstd.tgarch,"sstd")
t_sstd_AE_ES <- t_sstd_ES[2]
t_sstd_AE_p <- t_sstd_ES[[3]] 

t_std_ES <- ESTesting(tgarch.sstdback, VaR.std.tgarch,"std")
t_std_AE_ES <- t_std_ES[2]
t_std_AE_p <- t_std_ES[[3]] 

t_norm_ES <- ESTesting(tgarch.normback, VaR.norm.tgarch,"norm")
t_norm_AE_ES <- t_norm_ES[2]
t_norm_AE_p <- t_norm_ES[[3]]

#ES for nagarch

na_sged_ES <- ESTesting(nagarch.sgedback, VaR.sged.nagarch,"sged")
na_sged_AE_ES <- na_sged_ES[2]
na_sged_AE_p <- na_sged_ES[[3]] 

na_ged_ES <- ESTesting(nagarch.gedback, VaR.ged.nagarch,"ged")
na_ged_AE_ES <- na_ged_ES[2]
na_ged_AE_p <- na_ged_ES[[3]] 

na_sstd_ES <- ESTesting(nagarch.sstdback, VaR.sstd.nagarch,"sstd")
na_sstd_AE_ES <- na_sstd_ES[2]
na_sstd_AE_p <- na_sstd_ES[[3]] 

na_std_ES <- ESTesting(nagarch.sstdback, VaR.std.nagarch,"std")
na_std_AE_ES <- na_std_ES[2]
na_std_AE_p <- na_std_ES[[3]] 

na_norm_ES <- ESTesting(nagarch.normback, VaR.norm.nagarch,"norm")
na_norm_AE_ES <- na_norm_ES[2]
na_norm_AE_p <- na_norm_ES[[3]]

#ES for avgarch

av_sged_ES <- ESTesting(avgarch.sgedback, VaR.sged.avgarch,"sged")
av_sged_AE_ES <- av_sged_ES[2]
av_sged_AE_p <- av_sged_ES[[3]] 

av_ged_ES <- ESTesting(avgarch.gedback, VaR.ged.avgarch,"ged")
av_ged_AE_ES <- av_ged_ES[2]
av_ged_AE_p <- av_ged_ES[[3]] 

av_sstd_ES <- ESTesting(avgarch.sstdback, VaR.sstd.avgarch,"sstd")
av_sstd_AE_ES <- av_sstd_ES[2]
av_sstd_AE_p <- av_sstd_ES[[3]] 

av_std_ES <- ESTesting(avgarch.sstdback, VaR.std.avgarch,"std")
av_std_AE_ES <- av_std_ES[2]
av_std_AE_p <- av_std_ES[[3]] 

av_norm_ES <- ESTesting(avgarch.normback, VaR.norm.avgarch,"norm")
av_norm_AE_ES <- av_norm_ES[2]
av_norm_AE_p <- av_norm_ES[[3]]


```

```{r table4prep, echo=F}
e_sged <- gettests(VaR.sged.egarch)
e_ged <- gettests(VaR.ged.egarch)
e_sstd <- gettests(VaR.sstd.egarch)
e_std <- gettests(VaR.std.egarch)
e_norm <- gettests(VaR.norm.egarch)

gjr_sged <- gettests(VaR.sged.gjrgarch)
gjr_ged <- gettests(VaR.ged.gjrgarch)
gjr_sstd <- gettests(VaR.sstd.gjrgarch)
gjr_std <- gettests(VaR.std.gjrgarch)
gjr_norm <- gettests(VaR.norm.gjrgarch)

t_sged <- gettests(VaR.sged.tgarch)
t_ged <- gettests(VaR.ged.tgarch)
t_sstd <- gettests(VaR.sstd.tgarch)
t_std <- gettests(VaR.std.tgarch)
t_norm <- gettests(VaR.norm.tgarch)

na_sged <- gettests(VaR.sged.nagarch)
na_ged <- gettests(VaR.ged.nagarch)
na_sstd <- gettests(VaR.sstd.nagarch)
na_std <- gettests(VaR.std.nagarch)
na_norm <- gettests(VaR.norm.nagarch)

av_sged <- gettests(VaR.sged.avgarch)
av_ged <- gettests(VaR.ged.avgarch)
av_sstd <- gettests(VaR.sstd.avgarch)
av_std <- gettests(VaR.std.avgarch)
av_norm <- gettests(VaR.norm.avgarch)

#TABLE LAYOUT 

table_tests <- matrix(nrow=30,ncol=5)
rownames(table_tests) <- c("SGED","AE_var","AE_ES", "UC","CC","DQ","GED","AE_var","AE_ES","UC","CC","DQ","ST","AE_var","AE_ES","UC","CC","DQ","T","AE_var","AE_ES","UC","CC","DQ","Norm","AE_var","AE_ES","UC","CC","DQ")
colnames(table_tests) <- c("eGarch","gjrGarch","tGarch","naGarch","avGarch")

#STATISTICS

table_tests[2,] <- c(e_sged$ae, gjr_sged$ae,t_sged$ae,na_sged$ae,av_sged$ae)
table_tests[3,] <- c(as.numeric(e_sged_AE_ES), as.numeric(gjr_sged_AE_ES), as.numeric(t_sged_AE_ES), as.numeric(na_sged_AE_ES), as.numeric(av_sged_AE_ES))
table_tests[4,] <- c(e_sged$uc[1], gjr_sged$uc[1],t_sged$uc[1],na_sged$uc[1],av_sged$uc[1])
table_tests[5,] <- c(e_sged$cc[1], gjr_sged$cc[1],t_sged$cc[1],na_sged$cc[1],av_sged$cc[1])
table_tests[6,] <- c(e_sged$dq$stat, gjr_sged$dq$stat,t_sged$dq$stat,na_sged$dq$stat,av_sged$dq$stat)
table_tests[8,]<- c(e_ged$ae, gjr_ged$ae,t_ged$ae,na_ged$ae,av_ged$ae)
table_tests[9,] <- c(as.numeric(e_ged_AE_ES), as.numeric(gjr_ged_AE_ES), as.numeric(t_ged_AE_ES), as.numeric(na_ged_AE_ES), as.numeric(av_ged_AE_ES))
table_tests[10,]<- c(e_ged$uc[1], gjr_ged$uc[1],t_ged$uc[1],na_ged$uc[1],av_ged$uc[1])
table_tests[11,]<- c(e_ged$cc[1], gjr_ged$cc[1],t_ged$cc[1],na_ged$cc[1],av_ged$cc[1])
table_tests[12,]<- c(e_ged$dq$stat, gjr_ged$dq$stat,t_ged$dq$stat,na_ged$dq$stat,av_ged$dq$stat)
table_tests[14,]<- c(e_sstd$ae, gjr_sstd$ae,t_sstd$ae,na_sstd$ae,av_sstd$ae)
table_tests[15,] <- c(as.numeric(e_sstd_AE_ES), as.numeric(gjr_sstd_AE_ES), as.numeric(t_sstd_AE_ES), as.numeric(na_sstd_AE_ES), as.numeric(av_sstd_AE_ES))
table_tests[16,]<- c(e_sstd$uc[1], gjr_sstd$uc[1],t_sstd$uc[1],na_sstd$uc[1],av_sstd$uc[1])
table_tests[17,]<- c(e_sstd$cc[1], gjr_sstd$cc[1],t_sstd$cc[1],na_sstd$cc[1],av_sstd$cc[1])
table_tests[18,]<- c(e_sstd$dq$stat, gjr_sstd$dq$stat,t_sstd$dq$stat,na_sstd$dq$stat,av_sstd$dq$stat)
table_tests[20,]<- c(e_std$ae, gjr_std$ae,t_std$ae,na_std$ae,av_std$ae)
table_tests[21,] <- c(as.numeric(e_std_AE_ES), as.numeric(gjr_std_AE_ES), as.numeric(t_std_AE_ES), as.numeric(na_std_AE_ES), as.numeric(av_std_AE_ES))
table_tests[22,]<- c(e_std$uc[1], gjr_std$uc[1],t_std$uc[1],na_std$uc[1],av_std$uc[1])
table_tests[23,]<- c(e_std$cc[1], gjr_std$cc[1],t_std$cc[1],na_std$cc[1],av_std$cc[1])
table_tests[24,]<- c(e_std$dq$stat, gjr_std$dq$stat,t_std$dq$stat,na_std$dq$stat,av_std$dq$stat)
table_tests[26,]<- c(e_norm$ae, gjr_norm$ae,t_norm$ae,na_norm$ae,av_norm$ae)
table_tests[27,] <- c(as.numeric(e_norm_AE_ES), as.numeric(gjr_norm_AE_ES), as.numeric(t_norm_AE_ES), as.numeric(na_norm_AE_ES), as.numeric(av_norm_AE_ES))
table_tests[28,]<- c(e_norm$uc[1], gjr_norm$uc[1],t_norm$uc[1],na_norm$uc[1],av_norm$uc[1])
table_tests[29,]<- c(e_norm$cc[1], gjr_norm$cc[1],t_norm$cc[1],na_norm$cc[1],av_norm$cc[1])
table_tests[30,]<- c(e_norm$dq$stat, gjr_norm$dq$stat,t_norm$dq$stat,na_norm$dq$stat,av_norm$dq$stat)

#PVALUES LOOPS

#KABLE OUTPUT
df <- table_tests[-c(1,7,13,19,25),] %>% as.data.frame()
colnames(df) <- c("EGARCH", "GJRGARCH", "TGARCH", "NAGARCH", "AVGARCH")
row_group_label_fonts <- list(
list(bold = T, italic = T)
)
df <- as.matrix(df)
rownames(df) <- c("AE_var","AE_ES", "UC","CC","DQ","AE_var","AE_ES","UC","CC","DQ","AE_var","AE_ES","UC","CC","DQ","AE_var","AE_ES","UC","CC","DQ","AE_var","AE_ES","UC","CC","DQ")
```

<!--# description @stephane -->

\newpage

```{r table4, echo=F, results='asis'}
df %>% kbl(booktabs=T) %>% 
  kable_styling() %>%
  pack_rows("Panel A: SGED", 1,5) %>%
  pack_rows("Panel B: GED", 6,10) %>%
  pack_rows("Panel C: ST", 11,15) %>%
  pack_rows("Panel D: T", 16,20) %>%
  pack_rows("Panel E: N", 21,25) %>% add_indent(c(1:16, 18:20)) 
```

\clearpage

## Time-varying higher moments

```{r acdcode, eval = FALSE}
# ACD specification
sGARCH_ACDspec = racd::acdspec(mean.model = list(armaOrder = c(1, 0)), variance.model = list(variance.targeting = FALSE),distribution.model = list(model = 'sstd', skewOrder = c(1, 1, 1), shapeOrder = c(1,1,1), skewmodel = 'pwl', shapemodel = 'pwl'))

# sGARCH, takes 6 minutes
fit = racd::acdfit(sGARCH_ACDspec, R, solver = 'msoptim', solver.control = list(restarts = 10)) #very long process: starts from different starting values to find an optimum
```

```{r figureACDmoments, fig.cap = "Dynamics of the ACD model", fig.align='center', fig.subcap="This figure plots the conditional mean, the conditional volatility. The implied conditional time varying skewwness and excess kurtosis for the Euro Stoxx 50 series.", eval=FALSE}
par(mfrow = c(2, 2), mai = c(0.4, 0.75, 0.2, 0.3))
plot.zoo(fitted(fit),main = 'Conditional Mean', col = 'steelblue',xlab = "Time", ylab = "")
plot(as.zoo(abs(R)), main = 'Conditional Sigma',col = c('grey'),xlab = "Time", ylab = "");lines(as.zoo(sigma(fit)),col= 'steelblue'); legend(x="topleft", legend = c("absolute log-returns", "conditional volatility"), col = c('grey', 'steelblue'),lty = c(1,1), bty = 'n', cex = 0.8)

plot(as.zoo(racd::skewness(fit)), col = 'steelblue', ylab = "", main = 'Conditional Skewness',xlab = "Time")
plot(as.zoo(racd::kurtosis(fit)), col = 'steelblue', ylab = "", main = 'Conditional Excess Kurtosis',xlab = "Time")
```

```{r acdbacktest, echo=FALSE, eval=FALSE}
# cl = makePSOCKcluster(10)
# rollacd = racd::acdroll(sGARCH_ACDspec, data = R, n.start = 2500, refit.every = 500,refit.window = "moving", solver = "hybrid", calculate.VaR = TRUE, VaR.alpha = 0.05, cluster = cl,fit.control = list(), solver.control = list())
# stopCluster(cl)
# cl = makePSOCKcluster(10)
# rollacd = resume(rollacd, solver = 'optim')
# stopCluster(cl)
```

<!-- ## Backtest -->

```{r eval=FALSE}
model = c('sGARCH', 'iGARCH', 'eGARCH', 'gjrGARCH', 'fGARCH', 'fGARCH', 'fGARCH')
submodel = c(NA, NA, NA, NA, 'TGARCH', 'AVGARCH','NAGARCH')

spec1 <-  vector(mode = 'list', length = 7)
#.norm-----
for (i in 1:7) {
  spec1[[i]] = ugarchspec(mean.model = list(armaOrder = c(1, 0)), variance.model = list(model = model[i], submodel = if (i >= 5) submodel[i] else NULL))
}
#.ugarchroll-----
spec = c(spec1)
cluster = makePSOCKcluster(10)
clusterExport(cluster, c('spec', 'R'))
clusterEvalQ(cluster, library(rugarch))
# Out of sample estimation
n = length(spec)
fitlist = vector(mode = 'list', length = n)
start <- Sys.time()
for (i in 1:n) {
tmp = ugarchroll(spec[[i]], R, n.ahead = 1,n.start=2500, forecast.length = 1, refit.every = 252, refit.window = 'moving', solver = 'hybrid', calculate.VaR = FALSE, cluster = cluster, keep.coef = FALSE)
print(i)
if (!is.null(tmp@model$noncidx)) {
tmp = resume(tmp, solver = 'solnp', fit.control = list(scale = 1), solver.control = list(tol = 1e-07, delta = 1e-06), cluster = cluster)
print(i)
if (!is.null(tmp@model$noncidx))
fitlist[[i]] = NA
print(i)
} else {
fitlist[[i]] = as.data.frame(tmp, which = 'density')
}
print(i)
}
Sys.time() - start
```

```{r eval=FALSE}
vmodels = c('SGARCH(1,1)', 'IGARCH(1,1)', 'EGARCH(1,1)', 'GJRGARCH(1,1)', 'TGARCH(1,1)','AVGARCH(1,1)', 'NAGARCH(1,1)')
modelnames = c(paste(vmodels, '-NORM', sep = ''))
q1 = q5 = px = matrix(NA, ncol = 7, nrow = 6453)
dist = c(rep('norm', 7))
# use apply since nig and gh distributions are not yet vectorized
for (i in 1:7) {
q1[, i] = as.numeric(apply(fitlist[[i]], 1, function(x) qdist(dist[i], 0.01, mu = x['Mu'], sigma = x['Sigma'], skew = x['Skew'], shape = x['Shape'])))
q5[, i] = as.numeric(apply(fitlist[[i]], 1, function(x) qdist(dist[i], 0.05, mu = x['Mu'], sigma = x['Sigma'], skew = x['Skew'], shape = x['Shape'])))
px[, i] = as.numeric(apply(fitlist[[i]], 1, function(x) pdist(dist[i], x['Realized'], mu = x['Mu'], sigma = x['Sigma'], skew = x['Skew'], shape = x['Shape'])))
}
VaR1cc = apply(q1, 2, function(x) VaRTest(0.01, actual = fitlist[[1]][, 'Realized'], VaR = x))
VaR5cc = apply(q5, 2, function(x) VaRTest(0.05, actual = fitlist[[1]][, 'Realized'], VaR = x))
# VarCC01 = apply(q1, 2, function(x) VaRTest(qnorm(x), tail.test = TRUE, alpha = 0.01)$LRp)
# VarCC05 = apply(q5, 2, function(x) VaRTest(qnorm(x), tail.test = TRUE, alpha = 0.05)$LRp)
# BT1 = apply(px, 2, function(x) BerkowitzTest(qnorm(x), tail.test = TRUE, alpha = 0.01)$LRp)
# BT5 = apply(px, 2, function(x) BerkowitzTest(qnorm(x), tail.test = TRUE, alpha = 0.05)$LRp)
VTable = cbind(VaR1cc, VaR5cc)
rownames(VTable) = modelnames
colnames(VTable) = c('VaR.CC(1%)', 'VaR.CC(5%)')#, 'BT(1%)', 'BT(5%)')
```

```{r eval=FALSE}
dists <- regmatches(rownames(VTable),gregexpr("(?<=-).*",rownames(VTable),perl=T)) %>% unlist
garchmodel <- gsub("-.*","",rownames(VTable))

VTable <- as.data.frame(VTable)
V2Table <- VTable %>% mutate(dist = dists, model = garchmodel)
# V2Table <-V2Table %>% filter(dist != "NORM")
V2Table_long <- V2Table %>%
  gather("Stat", "Value", -c(dist, model))
ggplot(V2Table_long, aes(x=model, y = Value, fill=Stat)) +   geom_col(position = "dodge") + facet_wrap(~dist) + geom_hline(yintercept=0.05, 
                color = "blue", size=0.3) + geom_hline(yintercept=0.01,  
                color = "black", size=0.3) + 
scale_fill_manual("legend", values = c("VaR.CC(5%)" = "steelblue", "VaR.CC(1%)" = "grey")) + theme_bw() + theme(axis.text.x=element_text(angle = 90)) + theme(
    legend.position = "top",
    legend.box.just = "right",
    legend.margin = margin(1, 1, 1, 1)
    ) + theme(
    legend.box.background = element_rect(color="black", size=0.3),
    legend.box.margin = margin(2, 2, 2, 2)
) + theme(legend.title = element_blank())
```

# Robustness checks {#Robustness}

```{r eval=FALSE}
#LJUNG-BOX TEST

LJ.Test <- vector(mode = "list", length = length(Models.garch))
names(LJ.Test) <- Models.garch
for(i in 1:length(LJ.Test)){
  LJ.Test[[i]] <- matrix(NA, nrow = 2, ncol = length(distributions), dimnames = list(c("Statistic", "P Values"), names(Table.3)))
}
#create a function to make Lj box test(((Change the number 1 into how many days back you want to test)))

Lj.box.test.function <- function(garchmodel = garchfit.sGARCH, n.list = 1){
  tmp.1 <- Box.test(rugarch::residuals(garchmodel[[n.list]], standardize = T),1, "Ljung-Box") 
  test <- c(tmp.1$statistic, tmp.1$p.value)
  return(test)
}

for(i in 1:length(distributions)){
  LJ.Test[[1]][,i] <- Lj.box.test.function(garchmodel = garchfit.sGARCH, n.list = i)
    LJ.Test[[2]][,i] <- Lj.box.test.function(garchmodel = garchfit.eGARCH, n.list = i)
      LJ.Test[[3]][,i] <- Lj.box.test.function(garchmodel = garchfit.fGARCH.AVGARCH, n.list = i)
        LJ.Test[[4]][,i] <- Lj.box.test.function(garchmodel = garchfit.fGARCH.NAGARCH, n.list = i)
          LJ.Test[[5]][,i] <- Lj.box.test.function(garchmodel = garchfit.gjrGARCH, n.list = i)
            LJ.Test[[6]][,i] <- Lj.box.test.function(garchmodel = garchfit.fGARCH.TGARCH, n.list = i)
              LJ.Test[[7]][,i] <- Lj.box.test.function(garchmodel = garchfit.iGARCH, n.list = i)
                LJ.Test[[8]][,i] <- Lj.box.test.function(garchmodel = garchfit.EWMA, n.list = i)
}

LJ.Test <- lapply(LJ.Test, round, 3)

for(i in 1:length(LJ.Test)){
LJ.Test[[i]][1,which(LJ.Test[[i]][2,]>=0.10)] <- LJ.Test[[i]][1,which(LJ.Test[[i]][2,]>=0.10)]
LJ.Test[[i]][1,which(LJ.Test[[i]][2,]<0.10&LJ.Test[[i]][2,]>0.05)] <- paste0(LJ.Test[[i]][1,which(LJ.Test[[i]][2,]<0.10&LJ.Test[[i]][2,]>0.05)],"*")
LJ.Test[[i]][1,which(LJ.Test[[i]][2,]<=0.05&LJ.Test[[i]][2,]>0.01)] <- paste0(LJ.Test[[i]][1,which(LJ.Test[[i]][2,]<=0.05&LJ.Test[[i]][2,]>0.01)],"**")
LJ.Test[[i]][1,which(LJ.Test[[i]][2,]<=0.01)] <- paste0(LJ.Test[[i]][1,which(LJ.Test[[i]][2,]<=0.01)],"***")
LJ.Test[[i]] <- LJ.Test[[i]][-2,]
}

LJ.test.matrix <- cbind(LJ.Test[[1]],LJ.Test[[2]],LJ.Test[[3]],LJ.Test[[4]],LJ.Test[[5]],LJ.Test[[6]],LJ.Test[[7]],LJ.Test[[8]])
colnames(LJ.test.matrix) <- Models.garch.clean
LJ.test.df <- as.data.frame(LJ.test.matrix)

LJ.test.df %>% kbl(caption = "Ljung Box Test",
      label = 'LjboxTable',
      booktabs = T,
      position = "h!",
      digits = 3 )%>%
  kable_classic(full_width = F)%>%
  footnote(general = "Notes",number=c("This table shows the Ljung box statistics value for the respective model", "DESCRIBE PVALUES ***, **, *"),threeparttable = T,footnote_as_chunk = F, escape=F, general_title = "") %>%
  kable_styling(latex_options = "scale_down") %>% landscape()
```

```{r eval=FALSE}
#SIGNbias <- signbias(garchfit.sGARCH[[1]])
#Nyblom <- nyblom(garchfit.sGARCH[[1]])






#ARCH lm TEST

ARCH.lm.Test <- vector(mode = "list", length = length(Models.garch))
names(ARCH.lm.Test) <- Models.garch

#Create a function to make archlmtest ((((((change lags??????))))))
archlmtest = function (x, lags = 5, demean = FALSE, n.list = 1){
  x <- rugarch::residuals(x[[n.list]], standardize = T) 
	if(any(!is.finite(x))) x[!is.finite(x)] = 0
	x = as.vector(x)
	if(demean) x = scale(x, center = TRUE, scale = FALSE)
	lags = lags + 1
	mat = embed(x^2, lags)
	arch.lm = summary(lm(mat[, 1] ~ mat[, -1]))
	STATISTIC = arch.lm$r.squared * length(resid(arch.lm))
	names(STATISTIC) = "Chi-squared"
	PARAMETER = lags - 1
	names(PARAMETER) = "df"
	PVAL = 1 - pchisq(STATISTIC, df = PARAMETER)
	METHOD = "ARCH LM-test"
	result = list(statistic = STATISTIC, parameter = PARAMETER,
			p.value = PVAL, method = METHOD)
	class(result) = "htest"
	final <- c("Statistic"=result$statistic,"P Value" = result$p.value)
	return(final)
}
for(i in 1:length(ARCH.lm.Test)){
  ARCH.lm.Test[[i]] <- matrix(NA, nrow = 2, ncol = length(distributions), dimnames = list(c("Statistic", "P Values"), names(Table.3)))
}

for(i in 1:length(distributions)){
  ARCH.lm.Test[[1]][,i] <- archlmtest(x = garchfit.sGARCH, n.list = i)
    ARCH.lm.Test[[2]][,i] <- archlmtest(x = garchfit.eGARCH, n.list = i)
      ARCH.lm.Test[[3]][,i] <- archlmtest(x = garchfit.fGARCH.AVGARCH, n.list = i)
        ARCH.lm.Test[[4]][,i] <- archlmtest(x = garchfit.fGARCH.NAGARCH, n.list = i)
          ARCH.lm.Test[[5]][,i] <- archlmtest(x = garchfit.gjrGARCH, n.list = i)
            ARCH.lm.Test[[6]][,i] <- archlmtest(x = garchfit.fGARCH.TGARCH, n.list = i)
              ARCH.lm.Test[[7]][,i] <- archlmtest(x = garchfit.iGARCH, n.list = i)
                ARCH.lm.Test[[8]][,i] <- archlmtest(x = garchfit.EWMA, n.list = i)
}

ARCH.lm.Test <- lapply(ARCH.lm.Test, round, 3)

for(i in 1:length(ARCH.lm.Test)){
ARCH.lm.Test[[i]][1,which(ARCH.lm.Test[[i]][2,]>=0.10)] <- ARCH.lm.Test[[i]][1,which(ARCH.lm.Test[[i]][2,]>=0.10)]
ARCH.lm.Test[[i]][1,which(ARCH.lm.Test[[i]][2,]<0.10&ARCH.lm.Test[[i]][2,]>0.05)] <- paste0(ARCH.lm.Test[[i]][1,which(ARCH.lm.Test[[i]][2,]<0.10&ARCH.lm.Test[[i]][2,]>0.05)],"*")
ARCH.lm.Test[[i]][1,which(ARCH.lm.Test[[i]][2,]<=0.05&ARCH.lm.Test[[i]][2,]>0.01)] <- paste0(ARCH.lm.Test[[i]][1,which(ARCH.lm.Test[[i]][2,]<=0.05&ARCH.lm.Test[[i]][2,]>0.01)],"**")
ARCH.lm.Test[[i]][1,which(ARCH.lm.Test[[i]][2,]<=0.01)] <- paste0(ARCH.lm.Test[[i]][1,which(ARCH.lm.Test[[i]][2,]<=0.01)],"***")
ARCH.lm.Test[[i]] <- ARCH.lm.Test[[i]][-2,]
}

ARCH.lm.Test.matrix <- cbind(ARCH.lm.Test[[1]],ARCH.lm.Test[[2]],ARCH.lm.Test[[3]],ARCH.lm.Test[[4]],ARCH.lm.Test[[5]],ARCH.lm.Test[[6]],ARCH.lm.Test[[7]],ARCH.lm.Test[[8]])
colnames(ARCH.lm.Test.matrix) <- Models.garch.clean
ARCH.lm.Test.df <- as.data.frame(ARCH.lm.Test.matrix)

ARCH.lm.Test.df %>% kbl(caption = "ARCH LM Test",
      label = 'ARCHLMTable',
      booktabs = T,
      position = "h!",
      digits = 3 )%>%
  kable_classic(full_width = F)%>%
  footnote(general = "Notes",number=c("This table shows the ARCH LM statistics value for the respective model", "DESCRIBE PVALUES ***, **, *"),threeparttable = T,footnote_as_chunk = F, escape=F, general_title = "") %>%
  kable_styling(latex_options = "scale_down") %>% landscape()
```

## Specification checks

In order to check if the models are specified correctly, some specification checks have to be performed. The specification checks have to be done on the standardized residuals of the estimated GARCH model given by the following equation: $$ 
\hat{Z_t} = \dfrac{\hat{\varepsilon_t}}{\hat{\sigma_t}} = \dfrac{R_t - \hat{\mu}}{\hat{\sigma_t}}
$$ \#\#\# Figures control tests Autocorrelation function of the standardized residuals and autocorrelation function of the squared standardized residuals.

Then the density can be examined standardized residuals and compared with the normal distribution.

Also the QQ-plot can be examined.

### Residual heteroscedasticity

Ljung-Box test on the squared or absolute standardized residuals.

<!-- ### GMM test -->

zero-mean unit-variance not skewed no excess kurtosis no serial correlation in the squares no serial correlation in the cubes no serial correlation in the squares
