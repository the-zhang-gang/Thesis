---
output:
  bookdown::pdf_document2:
    template: templates/brief_template.tex
    citation_package: biblatex
  #bookdown::word_document2: default
  #bookdown::html_document2: default
documentclass: book
bibliography: references.bib
---

# Empirical Findings {#analysis}

\minitoc <!-- this will include a mini table of contents-->

## Density of the returns

```{r librariesfindings, include=F}
require(readxl)
require(xts)
require(PerformanceAnalytics)
require(kableExtra)
require(rugarch)
require(fitdistrplus)
require(fGarch)
require(tree)  # do we need this?
require(sgt)
require(devtools)
require(zoo)
require(parallel)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
# install_bitbucket("alexiosg/racd")
options(knitr.kable.NA = "")

data <- read_excel("data/datastream.xlsx",col_types = c("date", rep("numeric", 6)),skip = 2) #warnings are NA's
colnames(data) <- c("Date",gsub(pattern = " - PRICE INDEX", replacement='' , colnames(data)[2:7]))
Price_indices <- as.xts(data[,-1], order.by = data$Date)
Estoxx <- Price_indices[,1] #see if price index
R <- diff(Estoxx, log = TRUE, na.pad = FALSE)*100
require(readr)
```

### MLE distribution parameters
```{r mlesgt, echo=FALSE}
require(sgt)
require(graphics)
require(stats)
DistMLE <- function(R=R) {
  ### SGT
  X.data <- X ~ coredata(R)
  SGT_start <- list(mu=0,sigma=1, lambda = 0.5, p=2, q=8) # p = kappa, q = nu
  SGT_result <- sgt.mle(X.f = X.data, start = SGT_start)
  names(SGT_result$estimate) <- names(SGT_result$std.error) <-  c("alpha", "beta", "xi", "kappa", "eta")
  SGT_sumResult <- summary(SGT_result)
  SGT_AIC <- 2*length(SGT_result$estimate) - 2*SGT_sumResult$maximum
  SGT_pv <- 2* stats::pnorm(-abs(SGT_result$estimate/(SGT_result$std.error)))
  SGT_significance <- matrix(ncol = 5,nrow = 1)
  colnames(SGT_significance) <-  c("alpha", "beta", "xi", "kappa", "eta")
  for(i in 1:5){
  if(SGT_pv[i]>=0.10){
  SGT_significance[i] <-  ""
  }
  if(SGT_pv[i]<0.10){
  SGT_significance[i] <-  "*"  
  }
  if(SGT_pv[i]<0.05){
  SGT_significance[i] <-  "**"  
  }
  if(SGT_pv[i]<0.01){
  SGT_significance[i] <-  "***"  
  }
  }
  SGT_significance[is.na(SGT_significance)] <- ""

  ### SGED
  SGED_start <- list(mean=0,sd=1, nu = 2, xi = 1.5)
  SGED_result <- fitdist(data = as.vector(coredata(R)), distr = "sged", method = "mle", SGED_start)
  names(SGED_result$estimate) <- names(SGED_result$sd) <-  c("alpha", "beta", "kappa", "xi")
  SGED_sumResult <- summary(SGED_result)
  SGED_AIC <- 2*length(SGED_result$estimate-1) - 2*SGED_sumResult$loglik
  SGED_pv <- 2* stats::pnorm(-abs(SGED_result$estimate/(SGED_result$sd)))
  SGED_pv <- c(SGED_pv[1:2], SGED_pv[4], SGED_pv[3],NA)
  SGED_significance <- matrix(ncol =5,nrow = 1)
  colnames(SGED_significance) <-  c("alpha", "beta", "xi", "kappa", "eta")
  for(i in c(1:4)){
  if(SGED_pv[i]>=0.10){
  SGED_significance[i] <-  ""
  }
  if(SGED_pv[i]<0.10){
  SGED_significance[i] <-  "*"  
  }
  if(SGED_pv[i]<0.05){
  SGED_significance[i] <-  "**"  
  }
  if(SGED_pv[i]<0.01){
  SGED_significance[i] <-  "***"  
  }
  }
  SGED_significance[is.na(SGED_significance)] <- ""

  ### GED
  GED_start <- list(mean = 0, sd = 1, nu = 2)
  GED_result <- fitdist(data = as.vector(R),distr="ged", start = GED_start)
  names(GED_result$estimate) <- names(GED_result$sd) <-  c("alpha", "beta", "kappa")
  GED_sumResult <- summary(GED_result)
  GED_AIC <- 2*length(GED_result$estimate-2) - 2*GED_sumResult$loglik
  GED_pv <- 2* stats::pnorm(-abs(GED_sumResult$estimate/(GED_sumResult$sd)))
  GED_pv <- c(GED_pv[1:2], NA, GED_pv[3], NA)
  GED_significance <- matrix(ncol = 5,nrow = 1)
  colnames(GED_significance) <-  c("alpha", "beta", "xi", "kappa", "eta")
  for(i in c(1,2,4)){
  if(GED_pv[i]>=0.10){
  GED_significance[i] <-  ""
  }
  if(GED_pv[i]<0.10){
  GED_significance[i] <-  "*"  
  }
  if(GED_pv[i]<0.05){
  GED_significance[i] <-  "**"  
  }
    if(GED_pv[i]<0.01){
  GED_significance[i] <-  "***"  
  }
  }
  GED_significance[is.na(GED_significance)] <- ""

  ### ST (fitdist)
  ST_start <- list(mean=0,sd=1, nu = 5, xi=1.5)
  ST_result <- fitdistrplus::fitdist(data = as.vector(coredata(R)), distr = "sstd", method = "mle", ST_start)
  names(ST_result$estimate) <- names(ST_result$sd) <-  c("alpha", "beta", "eta","xi")
  ST_sumResult <- summary(ST_result)
  ST_sumResult$aic
  ST_pvalue <- 2*stats::pnorm(-abs(ST_sumResult$estimate/(ST_sumResult$sd)))
  ST_pvalue <-  c(ST_pvalue[1:2], ST_pvalue[4], NA, ST_pvalue[3])
  ST_significance <- matrix(ncol = 5,nrow = 1)
  colnames(ST_significance) <-  c("alpha", "beta", "xi", "kappa", "eta")
  for(i in c(1:3,5)){
  if(ST_pvalue[i]>=0.10){
  ST_significance[i] <-  ""
  }
  if(ST_pvalue[i]<0.10){
  ST_significance[i] <-  "*"  
  }
  if(ST_pvalue[i]<0.05){
  ST_significance[i] <-  "**"  
  }
    if(ST_pvalue[i]<0.01){
  ST_significance[i] <-  "***"  
  }
  }
  ST_significance[is.na(ST_significance)] <- ""

  ### T (fitdist)
  T_start <- list(mean = 0, sd = 1, nu = 5)
  T_result <- fitdistrplus::fitdist(data = as.vector(coredata(R)), distr = "std", method = "mle", T_start)
  names(T_result$estimate) <- names(T_result$sd) <-  c("alpha", "beta", "eta")
  T_sumResult <- summary(T_result)
  T_pvalues <-  2*stats::pnorm(-abs(T_result$estimate/(T_result$sd)))
  T_pvalues <-  c(T_pvalues[1:2], NA, NA, T_pvalues[3])
  T_significance <- matrix(ncol = 5,nrow = 1)
  colnames(T_significance) <-  c("alpha", "beta", "xi", "kappa", "eta")
  for(i in c(1,2,5)){
  if(T_pvalues[i]>=0.10){
  T_significance[i] <-  ""
  }
  if(T_pvalues[i]<0.10){
  T_significance[i] <-  "*"  
  }
  if(T_pvalues[i]<0.05){
  T_significance[i] <-  "**"  
  }
  if(T_pvalues[i]<0.01){
  T_significance[i] <-  "***"  
  }
  }
  T_significance[is.na(T_significance)] <- ""

  ### Normal (fitdist)
  Normal_start <- list(mean = 0, sd=1)
  Normal_result <- fitdist(as.vector(coredata(R)), "norm","mle", Normal_start)
  names(Normal_result$estimate) <- names(Normal_result$sd) <-  c("alpha", "beta")
  Normal_sumResult <- summary(Normal_result)
  Normal_AIC <- 2*length(Normal_result$estimate-3) - 2*Normal_sumResult$loglik
  Normal_pv <- 2*stats::pnorm(-abs(Normal_result$estimate/(Normal_result$sd)))
  Normal_significance <- matrix(ncol = 5,nrow = 1)
  colnames(Normal_significance) <-  c("alpha", "beta", "xi", "kappa", "eta")
  for(i in c(1:2)){
  if(Normal_pv[i]>=0.10){
  Normal_significance[i] <-  ""
  }
  if(Normal_pv[i]<0.10){
  Normal_significance[i] <-  "*"  
  }
  if(Normal_pv[i]<0.05){
  Normal_significance[i] <-  "**"  
  }
  if(Normal_pv[i]<0.01){
  Normal_significance[i] <-  "***"  
  }
  }
  Normal_significance[is.na(Normal_significance)] <- ""

#maximum likelihood estimates of unconditional distribution functions
Table2 <- matrix(nrow = 6, ncol = 7)
colnames(Table2) <- c("alpha","beta","xi","kappa","eta","LLH","AIC")
rownames(Table2) <- c("SGT","SGED","GED","ST","T","Normal")
# "alpha","beta","xi","kappa","nu","L","AIC"
Table2[1,1:5] <- SGT_result$estimate
Table2[1,6] <- SGT_result$maximum
Table2[1,7] <- SGT_AIC
# "alpha","beta","xi","kappa","nu","L","AIC"
Table2[2,1:2] <- SGED_result$estimate[1:2]
Table2[2,3] <- SGED_result$estimate[4] - 1
Table2[2,4] <- SGED_result$estimate[3]
Table2[2,5] <- Inf
Table2[2,6] <- SGED_result$loglik
Table2[2,7] <- SGT_AIC
# "alpha","beta","xi","kappa","nu","L","AIC"
Table2[3,1:2] <- GED_result$estimate[1:2]
Table2[3,3] <- 0
Table2[3,4] <- GED_result$estimate[3]
Table2[3,5] <- Inf
Table2[3,6] <- GED_result$loglik
Table2[3,7] <- GED_AIC
# "alpha","beta","xi","kappa","nu","L","AIC"
Table2[4,1:2] <- ST_result$estimate[1:2]
Table2[4,3] <- ST_result$estimate[4] - 1
Table2[4,4] <- 2
Table2[4,5] <- ST_result$estimate[3] # eta parameter is not exactly true here... See formula SGT package
Table2[4,6] <- ST_result$loglik
Table2[4,7] <- ST_result$aic
# "alpha","beta","xi","kappa","nu","L","AIC"
Table2[5,1:2] <- T_result$estimate[1:2]
Table2[5,3] <- 0
Table2[5,4] <- 2
Table2[5,5] <- T_result$estimate[3]/2 # eta parameters
Table2[5,6] <- T_result$loglik
Table2[5,7] <- T_result$aic

Table2[6,1:2] <- Normal_result$estimate[1:2]
Table2[6,3] <- 0
Table2[6,4] <- 2
Table2[6,5] <- Inf
Table2[6,6] <- Normal_result$loglik
Table2[6,7] <- Normal_result$aic

#adding SE
Table2_SE <- matrix(nrow = 12, ncol = 7)

Table2_SE <- as.data.frame(Table2_SE)
#coefficients placement
Table2_SE[1,] <- Table2[1,]
Table2_SE[3,] <- Table2[2,]
Table2_SE[5,] <- Table2[3,]
Table2_SE[7,] <- Table2[4,]
Table2_SE[9,] <- Table2[5,]
Table2_SE[11,] <- Table2[6,]
#fixing rownames, in a new column
colnames(Table2_SE) <- c("alpha","beta","xi","kappa","eta","L","AIC")
rownames(Table2_SE) <- 1:12
tablenames <- c("SGT","","SGED","","GED","","ST","","T","","Normal","")
Table2_SE <- cbind(tablenames,Table2_SE)
Table2_SE[c(1,3,5,7,9,11),-1] <- round(Table2_SE[c(1,3,5,7,9,11),-1], 3) #round

#SEs (basic)
# "alpha","beta","xi","kappa","eta","L","AIC"
Table2_SE[2,2:6] <- paste0("(",round(SGT_result$std.error, 3),")",SGT_significance)
# "alpha","beta","xi","kappa","eta","L","AIC"
#sd is correct, but the significance has to be fixed, same for GED, ST and T
Table2_SE[4,2:6] <- paste0("(",round(c(SGED_result$sd[1:2],SGED_result$sd[4], SGED_result$sd[3], NA),3),")", SGED_significance)
# "alpha","beta","xi","kappa","eta","L","AIC"
Table2_SE[6,2:6] <- paste0("(",round(c(GED_result$sd[1:2],NA,GED_result$sd[3],NA), 3),")",GED_significance)
# "alpha","beta","xi","kappa","eta","L","AIC"
Table2_SE[8,2:6] <- paste0("(",round(c(ST_result$sd[1:2],ST_result$sd[4],NA,ST_result$sd[3]),3),")",ST_significance)
# "alpha","beta","xi","kappa","eta","L","AIC"
Table2_SE[10,2:6] <- paste0("(",round(c(T_result$sd[-3],NA,NA,T_result$sd[3]),3),")",T_significance)
# "alpha","beta","xi","kappa","eta","L","AIC"
Table2_SE[12,2:6] <- paste0("(",round(c(Normal_result$sd, NA,NA,NA), 3),")",Normal_significance)


#Remove SE for limiting cases
# Table2_SE[6,4] <- NA
# Table2_SE[c(4,6),6] <- NA

totalresults <- list(table = Table2_SE, results = list(SGT = SGT_sumResult,SGED = SGED_sumResult, GED = GED_sumResult, ST = ST_sumResult, T = T_sumResult, Norm =Normal_sumResult))
return(totalresults)
}
```

```{r MLE tables for different series, include=FALSE, echo=FALSE}
R_dotcom <- window(R, start = "1987-01-01", end = "2001-12-31")
R_GFC <- window(R, start = "2002-01-01", end = "2009-03-31")
R_covid <- window(R, start = "2009-03-31")
length(R_dotcom); length(R_GFC); length(R_covid)

MLE_Full <- DistMLE(R)
MLE_dotcom <- DistMLE(R_dotcom)
MLE_GFC <- DistMLE(R_GFC)
MLE_covid <- DistMLE(R_covid)
```

In table \@ref(tab:MLEtable) we can see the estimated parameters of the unconditional distribution functions. They are presented for the Skewed Generalized T-distribution (SGT) and limiting cases thereof previously discussed. Additionally, maximum likelihood score and the Aikake Information Criterion (AIC) is reported to compare goodness of fit of the different distributions. We find that the SGT-distribution has the highest maximum likelihood score of all. All other distributions have relatively similar likelihood scores, though slightly lower and are therefore not the optimal distributions. However, when considering AIC it is a tie between SGT and SGED. This provides some indication that we have a valid case to test the suitability of different SGED-GARCH VaR models as an alternative for the SGT-GARCH VaR models. While sacrificing some goodness of fit, the SGED distribution has the advantage of requiring one less parameter, which could possibly result in less errors due to misspecification and easier implementation.  For the SGT parameters the standard deviation and skewness are both significant at the 1% level. For the SGED parameters, the standard deviation and the skewness are both significant at respectively the 1% and 5% level. Both distributions are right-skewed. For both distributions the shape parameters are significant at the 1% level, though the $q$ parameter was not estimated as it is by design set to infinity due to the SGED being a limiting case of SGT.^[To check whether the relative ranking of distributions still holds in different periods, we have calculated the maximum likelihood score and AIC for three smaller periods: The period up to the dotcom collapse (1987-2001), up to the GFC (2002-2009) and  up to the present Covid-crash (2009-2021). There is no qualitative difference in relative ranking with these subsamples. Results are reported in the appendix.]

Additionally, for every distribution fitted with MLE, plots are generated to compare the theoretical distribution with the observed returns. We see that except for the normal distribution which is quite off, the theoretical distributions are close to the actual data, except that they are too peaked. This problem is the least present for the SGT distribution.

```{r Euro Stoxx, echo=FALSE}
# par(mfrow = c(3,2), mar = c(1,4,3,3))
Eurostoxx <- DistMLE(R)
table2 <- Eurostoxx$table
table2[table2 == "(NA)"] <- NA
colnames(table2) <- c("", "$\\alpha$","$\\beta$","$\\xi$","$\\kappa$","$\\eta$","$LLH$","AIC")
# table2 <-  data.frame(table2, check.names = F, fix.empty.names = FALSE)
```

```{r table2final,echo=FALSE, results='asis'}
kbl(table2,col.names= c("$\\theta$", "$\\alpha$","$\\beta$","$\\xi$","$\\kappa$","$\\eta$","$LLH$","AIC") ,caption = "Maximum likelihood estimates of unconditional distribution functions",
      label = 'MLEtable',"latex",
      booktabs = T,
      position = "h!",
      digits = 3,
    escape=F
      )%>%
  kable_classic(full_width = F)%>%
  footnote(general = "Table contains parameter estimates for SGT-distribution and some of its limiting \\\\\\\\ cases. The underlying data is the daily return series of the Euro Stoxx 50 \\\\\\\\ for the period between December 31. 1986 and April 27. 2021. Standard errors are reported between brackets. $LLH$ is the maximum log-likelihood value. *, ** and *** point out significance at 10%, 5% and 1% level.",threeparttable = T,footnote_as_chunk = F, escape=F, general_title = "Notes") %>%
  kable_styling(latex_options = "scale_down")
```



## Constant higher moments

<!--# Here comes our main part [FILIPPO] -> to do!  -->

```{r garchcode, echo=FALSE}
distributions <- c("norm", "std", "sstd", "ged", "sged")
Models.garch <- c("sGARCH", "eGARCH","fGARCH.AVGARCH","fGARCH.NAGARCH", "gjrGARCH", "fGARCH.TGARCH", "iGARCH", "EWMA")
Models.garch.clean <-  toupper(gsub("fGARCH.", "", Models.garch)) # we use this for tables

for(i in 1:length(Models.garch)){
assign(paste0("garchspec.",Models.garch[i]),vector(mode = "list", length = length(distributions)))
assign(paste0("garchfit.",Models.garch[i]),vector(mode = "list", length = length(distributions)))
assign(paste0("stdret.",Models.garch[i]),vector(mode = "list", length = length(distributions)))
}

#.sGARCH--------------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.sGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "sGARCH", garchOrder = c(1,1), variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.sGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.sGARCH[[i]])
# Compute stdret using residuals()
stdret.sGARCH[[i]] <- residuals(garchfit.sGARCH[[i]], standardize = TRUE)
}

#.eGARCH-------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.eGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "eGARCH", variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.eGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.eGARCH[[i]])
# Compute stdret using residuals()
stdret.eGARCH[[i]] <- residuals(garchfit.eGARCH[[i]], standardize = TRUE)
}

#.fGARCH.NAGARCH------------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.fGARCH.NAGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "fGARCH", submodel = "NAGARCH", variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.fGARCH.NAGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.fGARCH.NAGARCH[[i]])
# Compute stdret using residuals()
stdret.fGARCH.NAGARCH[[i]] <- residuals(garchfit.fGARCH.NAGARCH[[i]], standardize = TRUE)
}

#.fGARCH.AVGARCH------------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.fGARCH.AVGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "fGARCH", submodel = "AVGARCH", variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.fGARCH.AVGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.fGARCH.AVGARCH[[i]])
# Compute stdret using residuals()
stdret.fGARCH.AVGARCH[[i]] <- residuals(garchfit.fGARCH.AVGARCH[[i]], standardize = TRUE)
}

#.gjrGARCH------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.gjrGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "gjrGARCH", variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.gjrGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.gjrGARCH[[i]])
# Compute stdret using residuals()
stdret.gjrGARCH[[i]] <- residuals(garchfit.gjrGARCH[[i]], standardize = TRUE)
}

#fGARCH.TGARCH-------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.fGARCH.TGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "fGARCH", submodel = "TGARCH", variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.fGARCH.TGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.fGARCH.TGARCH[[i]])
# Compute stdret using residuals()
stdret.fGARCH.TGARCH[[i]] <- residuals(garchfit.fGARCH.TGARCH[[i]], standardize = TRUE)
}

#.iGARCH--------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.iGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "iGARCH", variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.iGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.iGARCH[[i]])
# Compute stdret using residuals()
stdret.iGARCH[[i]] <- residuals(garchfit.iGARCH[[i]], standardize = TRUE)
}

#.csGARCH-----------------
# for(i in 1:length(distributions)){
# # Specify a GARCH model with constant mean
# garchspec.csGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
#                      variance.model = list(model = "csGARCH", variance.targeting = F),
#                      distribution.model = distributions[i])
# # Estimate the model
# garchfit.csGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.csGARCH[[i]])
# # Compute stdret using residuals()
# stdret.csGARCH[[i]] <- residuals(garchfit.csGARCH[[i]], standardize = TRUE)
# }


# we need EWMA
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.EWMA[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "iGARCH", variance.targeting = F),
                     distribution.model = distributions[i], fixed.pars = list(omega=0))
# Estimate the model
garchfit.EWMA[[i]] <- ugarchfit(data = R, spec = garchspec.EWMA[[i]])
# Compute stdret using residuals()
stdret.EWMA[[i]] <- residuals(garchfit.EWMA[[i]], standardize = TRUE)
}


#  make the histogram
#
# chart.Histogram(stdret.iGARCH[[1]], methods = c("add.normal","add.density" ),
#                 colorset = c("gray","red","blue"))
```


```{r table3prep, echo=FALSE}
require(plyr)
require(dplyr)
require(stringr)
Table.GARCH.function <- function(GARCHfit.object = garchfit.eGARCH){
#Making objects to fill   
list.table.3.tmp <- vector(mode = "list", length = length(distributions)*2)
list.table.3 <- vector(mode = "list", length = length(distributions))
names(list.table.3) <- distributions
ref.distr <- seq(from = 1, to = length(distributions)*2, by = 2)
#Retriving all the data from the original lists
for(i in 1:length(distributions)){
    list.table.3.tmp[[ref.distr[i]]] <- GARCHfit.object[[i]]@fit$coef
    list.table.3.tmp[[ref.distr[i]+1]] <- GARCHfit.object[[i]]@fit$tval
}
#From list of vectors of different lengths to list of matrixes with empty spaces filled with NAs
for(i in 1:length(distributions)){
  list.table.3[[i]] <- cbind(list.table.3.tmp[[ref.distr[i]]], list.table.3.tmp[[ref.distr[i]+1]][match(names(list.table.3.tmp[[ref.distr[i]]]), names(list.table.3.tmp[[ref.distr[i]+1]]))])
}
#Function to rearrange the list from a list of matrices to list of vectors
list.restructure <- function(object = list.table.3){
  len.table <- length(object)
  len.inside.list <- rep(NA, len.table)
  for(i in 1:len.table){len.inside.list[i] <- nrow(object[[i]])}
  adj.list <- vector(mode = "list", length = len.table)
  ref.list <- vector(mode = "list", length = len.table)
  names.list <- vector(mode = "list", length = len.table)
  for(i in 1:len.table){ref.list[[i]] <- seq(from = 1, to = len.inside.list[i]*2, by = 2)}
  for(i in 1:len.table){adj.list[[i]] <- names.list[[i]] <- rep(NA, len.inside.list[i]*2)}
  for(i in 1:len.table){
      adj.list[[i]][ref.list[[i]]] <- round(object[[i]][,1],3)
      adj.list[[i]][ref.list[[i]]+1] <- paste0("(", round(object[[i]][,2],3),")")
  }
  for(i in 1:len.table){
    names.list[[i]][ref.list[[i]]] <- rownames(object[[i]])
    names.list[[i]][ref.list[[i]]+1] <- paste0("p-val ",rownames(object[[i]]))
    #names.list[[i]][ref.list[[i]]+1] <- ""
    }
  names(adj.list) <- distributions
  for(i in 1:len.table){names(adj.list[[i]]) <- names.list[[i]]}
  return(adj.list)
}
#Unlisting and removing NAs
adj.list <- list.restructure(object = list.table.3)
table.3.matrix <- matrix(unlist(lapply(adj.list, `length<-`, max(lengths(adj.list)))),ncol = length(distributions),nrow = max(lengths(adj.list)), byrow = F)
colnames(table.3.matrix) <- names(adj.list)
table.3.matrix[is.na(table.3.matrix)] <- ""
table.3.matrix[table.3.matrix=="(NA)"] <- ""
#Adjustments for std & ged distributions
table.3.matrix[c(length(table.3.matrix[,2])-1,length(table.3.matrix[,2])),2] <- tail(table.3.matrix[table.3.matrix[,2]!="",2],2)
table.3.matrix[c(length(table.3.matrix[,2])-3,length(table.3.matrix[,2])-2),2] <- ""
table.3.matrix[c(length(table.3.matrix[,4])-1,length(table.3.matrix[,4])),4] <- tail(table.3.matrix[table.3.matrix[,4]!="",4],2)
table.3.matrix[c(length(table.3.matrix[,4])-3,length(table.3.matrix[,4])-2),4] <- ""
#Log-Likelyhoods
LLH <- rep(NA, length(distributions))
for(i in 1:length(distributions)){LLH[i] <- GARCHfit.object[[i]]@fit$LLH}
names.table.3 <- revalue(names(adj.list[[3]]), c("mu"="$\\alpha_0$", "ar1"="$\\alpha_1$", "omega"= "$\\beta_0$", "alpha1"="$\\beta_1$", "beta1"="$\\beta_2$", "gamma1"="$\\gamma$", "skew"="$\\xi$", "shape"="$\\kappa$", "eta11"="$rot$", "eta21"="$shift$"), warn_missing = F)
kappa.object <- cbind(matrix(data = "", nrow = 2, ncol = 3) ,table.3.matrix[(nrow(table.3.matrix)-1):(nrow(table.3.matrix)),4:5])
eta <- cbind(table.3.matrix[(nrow(table.3.matrix)-1):(nrow(table.3.matrix)),1:3], matrix(data = "", nrow = 2, ncol = 2) )
table.3.matrix[(nrow(table.3.matrix)-1):(nrow(table.3.matrix)),] <- kappa.object
table.3.matrix <- rbind(table.3.matrix, eta, round(LLH,3))
table.3.matrix <- cbind(c(names.table.3,"$\\eta$","p-val eta","$LLH$"), table.3.matrix)
table.3.matrix <- as.data.frame(table.3.matrix, row.names = c(names.table.3,"$\\eta$","","LLH"))
return(table.3.matrix)
}

#PARTIAL RESULTS

Table.3.iGARCH <- Table.GARCH.function(GARCHfit.object = garchfit.iGARCH)
Table.3.eGARCH <- Table.GARCH.function(GARCHfit.object = garchfit.eGARCH)
Table.3.gjrGARCH <- Table.GARCH.function(GARCHfit.object = garchfit.gjrGARCH)
Table.3.sGARCH <- Table.GARCH.function(GARCHfit.object = garchfit.sGARCH)
Table.3.EWMA <- Table.GARCH.function(GARCHfit.object = garchfit.EWMA)
Table.3.fGARCH.AVGARCH <- Table.GARCH.function(GARCHfit.object = garchfit.fGARCH.AVGARCH)
Table.3.fGARCH.NAGARCH <- Table.GARCH.function(GARCHfit.object = garchfit.fGARCH.NAGARCH)
Table.3.fGARCH.TGARCH <- Table.GARCH.function(GARCHfit.object = garchfit.fGARCH.TGARCH)

Table.3.function <- function(distribution = "sstd"){
ref <- which(names(Table.3.eGARCH)==distribution)#Reference column
#Taking all the relevant values
AVGARCH <- Table.3.fGARCH.AVGARCH[,c(1,ref)]
iGARCH <- Table.3.iGARCH[,c(1,ref)]
eGARCH <- Table.3.eGARCH[,c(1,ref)]
sGARCH <- Table.3.sGARCH[,c(1,ref)]
gjrGARCH <- Table.3.gjrGARCH[,c(1,ref)]
EWMA <- Table.3.EWMA[,c(1,ref)]
NAGARCH <- Table.3.fGARCH.NAGARCH[,c(1,ref)]
TGARCH <- Table.3.fGARCH.TGARCH[,c(1,ref)]
#Assigning the right names to columns
colnames(AVGARCH)[-1] <- rep("AVGARCH", length(colnames(AVGARCH)[-1]))
colnames(iGARCH)[-1] <- rep("iGARCH", length(colnames(iGARCH)[-1]))
colnames(eGARCH)[-1] <- rep("eGARCH", length(colnames(eGARCH)[-1]))
colnames(sGARCH)[-1] <- rep("sGARCH", length(colnames(sGARCH)[-1]))
colnames(gjrGARCH)[-1] <- rep("gjrGARCH", length(colnames(gjrGARCH)[-1]))
colnames(EWMA)[-1] <- rep("EWMA", length(colnames(EWMA)[-1]))
colnames(NAGARCH)[-1] <- rep("NAGARCH", length(colnames(NAGARCH)[-1]))
colnames(TGARCH)[-1] <- rep("TGARCH", length(colnames(TGARCH)[-1]))
#Binding all the columns & cleaning & ordering data
Table3 <- full_join(full_join(full_join(full_join(full_join(full_join(full_join(sGARCH, iGARCH),eGARCH),gjrGARCH),EWMA),NAGARCH),TGARCH),AVGARCH)
Table3[is.na(Table3)] <- ""
Table3 <- rbind(Table3[Table3[,1]!="$LLH$",], Table3[Table3[,1]=="$LLH$",])
Table3[substr(Table3[,1],1,5)=="p-val",1] <- ""
colnames(Table3) <- c("", colnames(Table3)[-1])
return(Table3)
}

Table.3 <- vector(mode = "list", length = length(distributions))
names(Table.3) <- c("Norm", "T", "ST", "GED", "SGED")
for(i in 1:length(distributions)){
  Table.3[[i]] <- suppressMessages(Table.3.function(distribution = distributions[i]))
}
#Kabling

fn1.3 <- sprintf(paste0('This table shows the maximum likelihood estimates of various ST-GARCH \\\\\\\\ models. The daily returns used on the ',str_to_title(gsub(pattern = '\\.', replacement=' ',colnames(R)))," Price index cover the  \\\\\\\\ periodfrom ",gsub(" UTC", "",format(min(index(R)), '%d %B, %Y'))," to ",gsub(" UTC", "",format(max(index(R)),'%d %B, %Y')), " (", nrow(R)," observations)."))
fn2.3 <- sprintf("The mean process is modeled as follows: $R_t= \\\\alpha_0+ \\\\alpha_1 \\\\times R_{t-1}+ \\\\varepsilon_t \\\\\\\\$ Where, in the %s GARCH models estimated, $\\\\gamma$ is the asymmetry in volatility \\\\\\\\, $\\\\xi, \\\\kappa$ and $\\\\eta$ are constant and $t$ statistics are displayed in parenthesis. \\\\\\\\$LLH$ is the maximized log likelihood value.", ncol(Table.3$ST)-1)





```
\noindent \@ref(tab:Table3) presents the maximum likelihood estimates for `r ncol(Table.3$ST)-1` symmetric and asymmetric GARCH models based on the ST distribution with constant skewness and kurtosis parameters ($t$ values are presented in parenthesis). The parameters in the conditional mean equations ($\alpha_0$) are all statistically significant with $t$ values from `r min(as.numeric(str_remove_all(Table.3$ST[2,-1], "[()]")))` to `r max(as.numeric(str_remove_all(Table.3$ST[2,-1], "[()]")))`. The AR(1) coefficient, $\alpha_1$, has parameters going from `r min(as.numeric(Table.3$ST[3,-1]))` to `r max(as.numeric(Table.3$ST[3,-1]))` with $t$ values ranging from `r min(as.numeric(str_remove_all(Table.3$ST[4,-1], "[()]")))` to `r max(as.numeric(str_remove_all(Table.3$ST[4,-1], "[()]")))` not suggesting a high significance and indicating slight negative autocorrelation. The GARCH parameters in the conditional variance equations ($\beta_0$) are generally statistically significant with $t$ values ranging from `r min(as.numeric(str_remove_all(Table.3$ST[6,-1], "[()]")), na.rm = TRUE)` to `r max(as.numeric(str_remove_all(Table.3$ST[6,-1], "[()]")), na.rm = TRUE)`. The results of $\beta_1$ and $\beta_2$ show the presence of significant time-variation in the conditional volatility of the Euro Stoxx 50 Price Index daily returns, in fact, the sum of $\beta_1$ and $\beta_2$ for the GARCH parameters is close to one (from `r min(as.numeric(str_remove_all(as.numeric(Table.3$ST[7,-1])+as.numeric(Table.3$ST[9,-1]), "[()]")), na.rm = TRUE)` to `r max(as.numeric(str_remove_all(as.numeric(Table.3$ST[7,-1])+as.numeric(Table.3$ST[9,-1]), "[()]")), na.rm = TRUE)`), suggesting the presence of persistence in the volatility of the returns. The parameter $\xi$ is highly significant for all the `r ncol(Table.3$ST)-1` models tested with values ranging from `r min(as.numeric(str_remove_all(Table.3$ST[11,-1], "[()]")), na.rm = TRUE)` to `r max(as.numeric(str_remove_all(Table.3$ST[11,-1], "[()]")), na.rm = TRUE)` confirming the presence of Skewness in the returns. The shape parameter $\eta$, which, in our case, measures the number of degrees of freedom, determining the tail behavior, is significant for all the models and ranges between `r min(as.numeric(str_remove_all(Table.3$ST[15,-1], "[()]")), na.rm = TRUE)` and `r max(as.numeric(str_remove_all(Table.3$ST[15,-1], "[()]")), na.rm = TRUE)`. The parameter $\gamma$, which is present only for eGARCH and gjrGARCH is significant and with values around `r round(mean(as.numeric(str_remove_all(Table.3$ST[17,-1], "[()]")), na.rm = TRUE),2)`. The absolute value function in fGARCH models (NAGARCH, TGARCH and AVGARCH) is subject to the $shift$ and the $rot$ parameters whose values are always positive and statistically significant. According to the log likelihood values ($LLH$), displayed in \@ref(tab:Table3), the model with the highest value is the `r colnames(Table.3$ST[,-1])[which.max(as.numeric(str_remove_all(Table.3$ST[23,-1], "[()]")))]` while, excluding the fGARCH models from the analysis, the model that performs best is the `r colnames(Table.3$ST[,-c(1,7,8,9)])[which.max(as.numeric(str_remove_all(Table.3$ST[23,-c(1,7,8,9)], "[()]")))]`.

```{r table3final, echo=F, results='asis'}
kbl(Table.3$ST, col.names = toupper(colnames(Table.3$ST)),caption = "Maximum likelihood estimates of the ST-GARCH models with constant skewness and kurtosis parameters","latex",
      label = 'Table3',
      booktabs = T, row.names = F, escape = F )%>%
  #kable_classic(full_width = F)%>%
  footnote(general = c(fn1.3,fn2.3),threeparttable = T,footnote_as_chunk = F, escape=F, general_title = "Notes")%>%
  kable_styling(latex_options = "scale_down")
```

\newpage
As you can see in table \@ref(tab:aicTable) the AIC for the skewed student's t-distribution (ST) is the best from all the models. As also shown in appendix part \@ref(goodness-of-fit). The best in all distributions of the GARCH models seems to be the NAGARCH model, but we do not want to overfit our models because of an in-sample estimation. That is why a parsimonous model like the EGARCH (which has the highest maximum likelihood for the standard GARCH models that are considered), but also the model AVGARCH will be examined using the ST distribution while it has the second-best (lowest) AIC.

```{r aictableprep, echo=F}
aic_sGARCH <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_sGARCH[i] = infocriteria(garchfit.sGARCH[[i]])[1]
}

aic_iGARCH <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_iGARCH[i] = infocriteria(garchfit.iGARCH[[i]])[1]
}

aic_EWMA <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_EWMA[i] = infocriteria(garchfit.EWMA[[i]])[1]
}

aic_eGARCH <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_eGARCH[i] = infocriteria(garchfit.eGARCH[[i]])[1]
}

aic_gjrGARCH <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_gjrGARCH[i] = infocriteria(garchfit.gjrGARCH[[i]])[1]
}

aic_naGARCH <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_naGARCH[i] = infocriteria(garchfit.fGARCH.NAGARCH[[i]])[1]
}

aic_tGARCH <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_tGARCH[i] = infocriteria(garchfit.fGARCH.TGARCH[[i]])[1]
}

aic_avgarch <- vector(length=length(distributions))
for (i in 1:length(distributions)) {
  aic_avgarch[i] = infocriteria(garchfit.fGARCH.AVGARCH[[i]])[1]
}

aics <- matrix(ncol=length(Models.garch), nrow = length(distributions))
rownames(aics) <- distributions
colnames(aics) <- Models.garch.clean[c(1,7,8,2,5,4,6,3)]
aics[,1] <- aic_sGARCH
aics[,2] <- aic_iGARCH
aics[,3] <- aic_EWMA
aics[,4] <- aic_eGARCH
aics[,5] <- aic_gjrGARCH
aics[,6] <- aic_naGARCH
aics[,7] <- aic_tGARCH
aics[,8] <- aic_avgarch

tableAIC <- as.data.frame(round(aics,4))
# try 2
tableAIC$SGARCH = cell_spec(tableAIC$SGARCH, color = ifelse(tableAIC$SGARCH==min(tableAIC$SGARCH), "green", "black"))

# for ourselves: quick conditional formatting
#require(condformat)
# cf <-  condformat(tableAIC) %>%
#   rule_fill_discrete(SGARCH,expression =SGARCH==min(SGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(IGARCH,expression =IGARCH==min(IGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(EWMA,expression =EWMA==min(EWMA), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(EGARCH,expression =EGARCH==min(EGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(GJRGARCH,expression =GJRGARCH==min(GJRGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(NAGARCH,expression =NAGARCH==min(NAGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen"))  %>%
#   rule_fill_discrete(TGARCH,expression =TGARCH==min(TGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(AVGARCH,expression =AVGARCH==min(AVGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen"))
```


```{r aictablelatex, echo=F, results='asis'}
aics %>% kbl(caption = "Model selection according to AIC",format = "latex",
      label = 'aicTable',
      booktabs = T,
      position = "h!",
      digits = 3 )%>%
  kable_classic(full_width = F)%>%
  footnote(general = "Notes",number="This table shows the AIC value for the respective model",threeparttable = T,footnote_as_chunk = F, escape=F, general_title = "") %>%
  kable_styling(latex_options = "scale_down")
```

\newpage
### Value-at-risk
As already mentioned 3 candidate models seem to be candidates to check if they perform well using a forecasting technique and backtest. This includes the EGARCH, the NAGARCH and AVGARCH. A simple graph is shown in figure \@ref(fig:figVaRinsample) for the EGARCH-ST model. It seems that the VaR model for $\alpha=0.05$ underestimates the downside events, while the VaR model for $\alpha=0.01$ overestimates a lot of the downside events.
```{r figVaRinsample, fig.cap="Value-at-Risk (in-sample) for the EGARCH-ST model", fig.align='center', out.width='50%', echo=FALSE}
par(mfrow = c(2,1))
Conditional.variance <- sigma(garchfit.eGARCH[[3]])
Conditional.mean <- fitted(garchfit.eGARCH[[3]])
n <- garchfit.eGARCH[[3]]@fit$coef["shape"]
VaR05 <- as.numeric(Conditional.mean + Conditional.variance*qdist("sstd",p=0.05,
shape = coef(garchfit.eGARCH[[3]])["shape"],skew  = coef(garchfit.eGARCH[[3]])["skew"]))
par(mai = c(0.4, 2, 0, 2))
plot(as.matrix(R), type = "l" , xlab = "" ,
ylab = "95% VaR value", col = "darkgray"); lines(VaR05,col = adjustcolor("red",alpha.f=0.5)); legend ("topleft", bty = "n", lty = c (1,1) , col = c("darkgrey", adjustcolor("red" ,alpha.f =0.5)) ,legend = c(expression(R[t]), expression(VaR[0.05][","][t])))

VaR01 <- as.numeric(Conditional.mean + Conditional.variance*qdist("sstd",p=0.01,
shape = coef(garchfit.eGARCH[[3]])["shape"],skew  = coef(garchfit.eGARCH[[3]])["skew"]))
par(mai = c(0.8, 2, 0.2, 2))
plot(as.matrix(R), type = "l" , xlab = "T" ,
ylab = "99% VaR value", col = "darkgray"); lines(VaR01, col = adjustcolor("green",alpha.f=0.5)); legend ("topleft", bty = "n", lty = c (1,1) , col = c("darkgrey", adjustcolor("green" ,alpha.f =0.5)) ,legend = c(expression(R[t]), expression(VaR[0.01][","][t])))
```

Let us examine this further using a moving window approach whilst forecasting 1-day ahead results with a window size of 1500. Figure \@ref(fig:figbacktest) shows that choosing an appropriate forecast period is important, while it includes the decline in 2016 with among which Brexit and the recent COVID-crisis.
```{r figbacktest, out.width='70%', fig.align='center', echo=FALSE}
par(mfrow = c(1,1), mar = c(2, 2, 2, 2))
xtsExtra::plot.xts(Estoxx, col = 'steelblue', screens = 1, blocks = list(start.time = paste(head(tail(index(Estoxx),1500), 1)), end.time = paste(index(tail(Estoxx, 1))), col = 'grey90'), main = 'Euro Stoxx 50', minor.ticks = FALSE)
```

\newpage
```{r garchroll, eval = FALSE, echo = FALSE}
#VaR garchroll forecasting and backtesting skewed student t
# EGARCH parsimonous model sstd
backtest1<-ugarchroll(garchspec.eGARCH[[3]],data=R,n.ahead=1,forecast.length=1500,refit.every=50,refit.window="moving",windows.size = 1500, solver="hybrid", fit.control=list(), solver.control=list(), calculate.VaR=TRUE,VaR.alpha=c(0.01,0.05), keep.coef=TRUE)
Repbacktest1<- report(backtest1,type="VaR",VaR.alpha=0.01,conf.level=0.99)
Repbacktest2<-report(backtest1,type="VaR",VaR.alpha=0.05,conf.level=0.95)
# NAGARCH sstd
backtest2 <-ugarchroll(garchspec.fGARCH.NAGARCH[[3]],data=R,n.ahead=1,forecast.length=1500,refit.every=50,refit.window="moving",windows.size = 1500, solver="hybrid", fit.control=list(), solver.control=list(), calculate.VaR=TRUE,VaR.alpha=c(0.01,0.05), keep.coef=TRUE)
Repbacktest3<-report(backtest2,type="VaR",VaR.alpha=0.01,conf.level=0.99)
Repbacktest4<-report(backtest2,type="VaR",VaR.alpha=0.05,conf.level=0.95)
#
# backtest3 <-ugarchroll(garchspec.fGARCH.AVGARCH[[3]],data=R,n.ahead=1,forecast.length=1500,refit.every=50,refit.window="moving",windows.size = 1500, solver="hybrid", fit.control=list(), solver.control=list(), calculate.VaR=TRUE,VaR.alpha=c(0.01,0.05), keep.coef=TRUE)
# Repbacktest5<-report(backtest3,type="VaR",VaR.alpha=0.01,conf.level=0.99)
# Repbacktest6<-report(backtest3,type="VaR",VaR.alpha=0.05,conf.level=0.95)
```
As you can see in figure \@ref(fig.)
```{r figurebacktests2,fig.cap = "Comparison between VaR-EGARCH-ST and VaR-NAGARCH-N", fig.align='center', echo=FALSE, eval = FALSE}
# EGARCH with sstd vs NAGARCH with sstd
par(mfrow = c(3,2), mar = c(2.5,2.5,1.5,2.5))
# EGARCH with SSTD
plot(backtest1,which=4,VaR.alpha=c(0.01),
legend("topright",bty="n",legend= bquote(~ alpha == "0.01"))
title(main = "EGARCH-ST (1%)")
plot(backtest1,which=4,VaR.alpha=0.05)
legend("topright",bty="n",legend= bquote(~ alpha == "0.05"))
title(main = "EGARCH-ST (5%)")

# NAGARCH with SSTD
plot(backtest5NAGARCHST,which=4,Var.alpha=0.01)
legend("topright",bty="n",legend= bquote(~ alpha == "0.01"))
title(main = "NAGARCH-ST (1%)")
plot(backtest6NAGARCHST,which=4,VaR.alpha=0.05)
legend("topright",bty="n",legend= bquote(~ alpha == "0.05"))
title(main = "NAGARCH-ST (5%)")

# AVGARCH with SSTD
plot(backtest7AVGARCHST,which=4,Var.alpha=0.01)
legend("topright",bty="n",legend= bquote(~ alpha == "0.01"))
title(main = "NAGARCH-ST (1%)")
plot(backtest8AVGARCHST,which=4,VaR.alpha=0.05)
legend("topright",bty="n",legend= bquote(~ alpha == "0.05"))
title(main = "NAGARCH-ST (5%)")
```

### Expected shortfall
```{r}
# Bootstrap Test for the Expected Shortfall?
# V-TEST?

# what's in rugarch?
```

\clearpage
## Time-varying higher moments
```{r acdcode, echo = FALSE}
# ACD specification
sGARCH_ACDspec = racd::acdspec(mean.model = list(armaOrder = c(1, 0)), variance.model = list(variance.targeting = FALSE),
distribution.model = list(model = 'sstd', skewOrder = c(1, 1, 1), shapeOrder = c(1,1,1), skewmodel = 'quad', shapemodel = 'quad'))

# sGARCH, takes 6 minutes
cl = makePSOCKcluster(10)
fit = racd::acdfit(sGARCH_ACDspec, R, solver = 'msoptim', solver.control = list(restarts = 10),cluster = cl) #very long process: starts from different starting values to find an optimum

rollacd = racd::acdroll(spec = sGARCH_ACDspec, data = R, n.ahead = 1, refit.every = 50, refit.window = "moving", window.size = NULL, forecast.length = 1500, solver = "msoptim", calculate.VaR = TRUE, VaR.alpha = c(0.01,0.05), keep.coef = TRUE,  solver.control =list(restarts = 10))
```

```{r figureACDmoments, fig.cap = "Dynamics of the ACD model", fig.align='center', fig.subcap="This figure plots the conditional mean, the conditional volatility. The implied conditional time varying skewwness and excess kurtosis for the Euro Stoxx 50 series.",, echo=FALSE}
par(mfrow = c(2, 2), mai = c(0.4, 0.75, 0.2, 0.3))
plot.zoo(fitted(fit),main = 'Conditional Mean', col = 'steelblue',xlab = "Time", ylab = "")
plot(as.zoo(abs(R)), main = 'Conditional Sigma',col = c('grey'),xlab = "Time", ylab = "");lines(as.zoo(sigma(fit)),col= 'steelblue'); legend(x="topleft", legend = c("absolute log-returns", "conditional volatility"), col = c('grey', 'steelblue'),lty = c(1,1), bty = 'n', cex = 0.8)

plot(as.zoo(racd::skewness(fit)), col = 'steelblue', ylab = "", main = 'Conditional Skewness',xlab = "Time")
plot(as.zoo(racd::kurtosis(fit)), col = 'steelblue', ylab = "", main = 'Conditional Excess Kurtosis',xlab = "Time")
```
oll