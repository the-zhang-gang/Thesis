---
output:
  bookdown::pdf_document2:
    template: templates/brief_template.tex
    citation_package: biblatex
  #bookdown::word_document2: default
  #bookdown::html_document2: default
documentclass: book
bibliography: references.bib
---

# Empirical Findings {#analysis}

\minitoc <!-- this will include a mini table of contents-->

## Density of the returns
```{r include=F}
require(readxl)
require(xts)
require(PerformanceAnalytics)
require(kableExtra)
require(rugarch)
require(fitdistrplus)
require(fGarch) 
require(tree)  # do we need this?
require(sgt)
require(devtools)
require(condformat)
require(zoo)
# install_bitbucket("alexiosg/racd")
options(knitr.kable.NA = "")

data <- read_excel("data/datastream.xlsx",col_types = c("date", rep("numeric", 6)),skip = 2) #warnings are NA's
colnames(data) <- c("Date",gsub(pattern = " - PRICE INDEX", replacement='' , colnames(data)[2:7]))
Price_indices <- as.xts(data[,-1], order.by = data$Date)
Estoxx <- Price_indices[,1] #see if price index
R <- diff(Estoxx, log = TRUE, na.pad = FALSE)*100
```

### MLE distribution parameters

```{r SGTMLE, include=FALSE}
par(mfrow = c(3,2))
sgt.mle2 <- function (X.f, mu.f = mu ~ mu, sigma.f = sigma ~ sigma, lambda.f = lambda ~ lambda, p.f = p ~ p, q.f = q ~ q, data = parent.frame(), start, subset, method = "BFGS", itnmax = NULL, hessian.method = "Richardson", gradient.method = "Richardson", mean.cent = TRUE, var.adj = TRUE, ..., lower =-Inf, upper=Inf) 
  { formList = list(X = X.f, mu = mu.f, sigma = sigma.f, lambda = lambda.f, 
                  p = p.f, q = q.f)
  varNames = NULL
  envir = new.env()
  for (i in 1:6) {
    formList[[i]] = stats::as.formula(formList[[i]])
    if (length(formList[[i]]) == 2L) {
      formList[[i]][[3L]] = formList[[i]][[2L]]
      formList[[i]][[2L]] = as.name(names(formList)[i])
    }
    else if (as.character(formList[[i]][[2L]]) != names(formList)[i]) {
      warning(paste("The left hand side of ", names(formList)[i], 
                    ".f was changed from ", as.character(formList[[i]][[2L]]), 
                    " to ", names(formList)[i], sep = ""))
    }
    varNames = c(varNames, all.vars(formList[[i]][[3L]]))
  }
  if (class(data)[1L] == "matrix") 
    data = as.data.frame(data)
  if (!is.list(data) && !is.environment(data)) 
    stop("'data' must be a list or an environment")
  start = as.list(start)
  if (is.null(names(start))) 
    stop("'start' must be a named list or named numeric vector")
  if ("" %in% names(start)) 
    stop("at least one of the elements in 'start' is missing a name")
  parNames = names(start)
  varNames = varNames[is.na(match(varNames, parNames))]
  if (length(varNames) == 0L) 
    stop("there is no reference to data in the given formulas")
  for (i in varNames) {
    if (!exists(i, data)) 
      stop(paste(i, "is not contained in 'start' and it is not found in 'data'"))
    assign(i, eval(parse(text = paste("as.numeric(data$", 
                                      i, ")", sep = ""))), envir)
  }
  if (length(varNames) > 1) {
    for (i in 2:length(varNames)) {
      if (length(eval(parse(text = paste("envir$", varNames[1L], 
                                         sep = "")))) != length(eval(parse(text = paste("envir$", 
                                                                                        varNames[i], sep = ""))))) 
        stop(paste("the length of the variable", varNames[i], 
                   "does not match the length of the variable", 
                   varNames[1L]))
    }
  }
  control = list(...)
  if (!is.null(control$maximize)) 
    stop("'maximize' option not allowed")
  if (!missing(subset)) 
    for (i in varNames) assign(i, eval(parse(text = paste("envir$", 
                                                          i, "[subset]", sep = ""))), envir)
  keep = rep(TRUE, length(eval(parse(text = paste("envir$", 
                                                  varNames[1L], sep = "")))))
  for (i in varNames) keep = keep & is.finite(eval(parse(text = paste("envir$", 
                                                                      i, sep = ""))))
  for (i in varNames) assign(i, eval(parse(text = paste("envir$", 
                                                        i, "[keep]", sep = ""))), envir)
  loglik = function(params) {
    for (i in 1:length(parNames)) assign(parNames[i], unlist(params[i]))
    X = eval(formList[[1L]][[3L]])
    mu = eval(formList[[2L]][[3L]])
    sigma = eval(formList[[3L]][[3L]])
    lambda = eval(formList[[4L]][[3L]])
    p = eval(formList[[5L]][[3L]])
    q = eval(formList[[6L]][[3L]])
    sum(dsgt(X, mu, sigma, lambda, p, q, mean.cent, var.adj, 
             log = TRUE))
  }
  environment(loglik) = envir
  negloglik = function(params) {
    -loglik(params)
  }
  if (!is.finite(loglik(start))) 
    stop("'start' yields infinite or non-computable SGT function values")
  optimum = suppressWarnings(optimx::optimx(par = unlist(start), 
                                            fn = negloglik, method = method, itnmax = itnmax, control = control, lower=lower, upper=upper))
  minimum = min(optimum$value, na.rm = TRUE)
  if (!is.finite(minimum)) 
    stop("All Maximization Methods Failed")
  whichbest = max(which(minimum == optimum$value))
  optimal = optimum[whichbest, ]
  estimate = as.numeric(optimum[whichbest, 1:length(parNames)])
  names(estimate) = parNames
  H = tryCatch(numDeriv::hessian(loglik, estimate, method = hessian.method), 
               error = function(e) {
                 warning("hessian matrix calculation failed")
                 return(as.matrix(NaN))
               })
  varcov = tryCatch(-qr.solve(H), error = function(e) {
    warning("covariance matrix calculation failed due to a problem with the hessian")
    return(as.matrix(NaN))
  })
  std.error = sqrt(diag(varcov))
  if (is.finite(varcov[1, 1])) 
    names(std.error) = parNames
  gradient = tryCatch(numDeriv::grad(loglik, estimate, method = gradient.method), 
                      error = function(e) {
                        warning("gradient calculation failed")
                        return(NaN)
                      })
  result = list(maximum = -minimum, estimate = estimate, convcode = as.numeric(optimal$convcode), 
                niter = as.numeric(optimal$niter), best.method.used = row.names(optimal), 
                optimx = optimum, hessian = H, gradient = gradient, 
                varcov = varcov, std.error = std.error)
  class(result) = c("sgtest", class(result))
  return(result)
}
```

```{r mlesgt, include=FALSE}
library(sgt)
require(graphics)
require(stats)
DistMLE <- function(R) {
  ### SGT
  X.data <- X ~ coredata(R)
  SGT_start <- list(mu=0,sigma=2, lambda = 0.5, p=2, q=8) # p = kappa, q = nu
  SGT_result <- sgt.mle2(X.f = X.data, start = SGT_start)
  SGT_sumResult <- summary(SGT_result)
  SGT_AIC <- 2*length(SGT_result$estimate) - 2*SGT_sumResult$maximum
  SGT_pv <- SGT_sumResult$p.value
  SGT_significance <- matrix(ncol = 5,nrow = 1)
  for(i in 1:5){
  if(SGT_pv[i]>=0.10){
  SGT_significance[i] <-  "" 
  }
  if(SGT_pv[i]<0.10){
  SGT_significance[i] <-  "*"  
  }
  if(SGT_pv[i]<0.05){
  SGT_significance[i] <-  "**"  
  }
  if(SGT_pv[i]<0.01){
  SGT_significance[i] <-  "***"  
  }
  }
  SGT_significance[is.na(SGT_significance)] <- ""
  
  ### SGED
  SGED_start <- list(mean=0,sd=1, nu = 2, xi = 1.5)
  SGED_result <- fitdist(data = as.vector(coredata(R)), distr = "sged", method = "mle", SGED_start_f)
  SGED_sumResult <- summary(SGED_result)
  SGED_AIC <- 2*length(SGED_result$estimate-1) - 2*SGED_sumResult$loglik
  SGED_pv <- 2* stats::pnorm(-abs(SGED_result$estimate/(SGED_result$sd)))
  SGED_pv <- c(SGED_pv[1:2], SGED_pv[4],NA, SGED_pv[3])
  SGED_significance <- matrix(ncol =5,nrow = 1)
  for(i in c(1:3,5)){
  if(SGED_pv[i]>=0.10){
  SGED_significance[i] <-  "" 
  }
  if(SGED_pv[i]<0.10){
  SGED_significance[i] <-  "*"  
  }
  if(SGED_pv[i]<0.05){
  SGED_significance[i] <-  "**"  
  }
  if(SGED_pv[i]<0.01){
  SGED_significance[i] <-  "***"  
  }
  }
  SGED_significance[is.na(SGED_significance)] <- ""
  
  ### GED
  GED_start <- list(mean = 0, sd = 1, nu = 2)
  GED_result <- fitdist(data = as.vector(R),distr="ged", start = GED_start)
  GED_sumResult <- summary(GED_result)
  GED_AIC <- 2*length(GED_result$estimate-2) - 2*GED_sumResult$loglik
  GED_pv <- 2* stats::pnorm(-abs(GED_sumResult$estimate/(GED_sumResult$sd)))
  GED_pv <- c(GED_pv[1:2], NA, NA, GED_pv[3])
  GED_significance <- matrix(ncol = 5,nrow = 1)
  for(i in c(1,2,5)){
  if(GED_pv[i]>=0.10){
  GED_significance[i] <-  "" 
  }
  if(GED_pv[i]<0.10){
  GED_significance[i] <-  "*"  
  }
  if(GED_pv[i]<0.05){
  GED_significance[i] <-  "**"  
  }
    if(GED_pv[i]<0.01){
  GED_significance[i] <-  "***"  
  }
  }
  GED_significance[is.na(GED_significance)] <- ""
  
  ### ST (fitdist) 
  ST_start <- list(mean=0,sd=1, nu = 5, xi=1.5)
  ST_result <- fitdistrplus::fitdist(data = as.vector(coredata(R)), distr = "sstd", method = "mle", ST_start)
  ST_sumResult <- summary(ST_result)
  ST_sumResult$aic
  ST_pvalue <- 2*stats::pnorm(-abs(ST_sumResult$estimate/(ST_sumResult$sd)))
  ST_pvalue <-  c(ST_pvalue[1:2], ST_pvalue[4], NA, ST_pvalue[3])
  ST_significance <- matrix(ncol = 5,nrow = 1)
  for(i in c(1:3,5)){
  if(ST_pvalue[i]>=0.10){
  ST_significance[i] <-  "" 
  }
  if(ST_pvalue[i]<0.10){
  ST_significance[i] <-  "*"  
  }
  if(ST_pvalue[i]<0.05){
  ST_significance[i] <-  "**"  
  }
    if(ST_pvalue[i]<0.01){
  ST_significance[i] <-  "***"  
  }
  }
  ST_significance[is.na(ST_significance)] <- ""
  
  ### T (fitdist) 
  T_start <- list(mean = 0, sd = 1, nu = 5)
  T_result <- fitdistrplus::fitdist(data = as.vector(coredata(R)), distr = "std", method = "mle", T_start)
  T_sumResult <- summary(T_result)
  T_pvalues <-  2*stats::pnorm(-abs(T_result$estimate/(T_result$sd)))
  T_pvalues <-  c(T_pvalues[1:2], NA, NA, T_pvalues[3])
  T_significance <- matrix(ncol = 5,nrow = 1)
  for(i in c(1,2,5)){
  if(T_pvalues[i]>=0.10){
  T_significance[i] <-  "" 
  }
  if(T_pvalues[i]<0.10){
  T_significance[i] <-  "*"  
  }
  if(T_pvalues[i]<0.05){
  T_significance[i] <-  "**"  
  }
  if(T_pvalues[i]<0.01){
  T_significance[i] <-  "***"  
  }
  }
  T_significance[is.na(T_significance)] <- ""
  
  ### Normal (fitdist)
  Normal_start <- list(mean = 0, sd=1)
  Normal_result <- fitdist(as.vector(coredata(R)), "norm","mle", Normal_start)
  Normal_sumResult <- summary(Normal_result)
  Normal_AIC <- 2*length(Normal_result$estimate-3) - 2*Normal_sumResult$loglik
  Normal_pv <- 2*stats::pnorm(-abs(Normal_result$estimate/(Normal_result$sd)))
  Normal_significance <- matrix(ncol = 5,nrow = 1)
  for(i in c(1:2)){
  if(Normal_pv[i]>=0.10){
  Normal_significance[i] <-  "" 
  }
  if(Normal_pv[i]<0.10){
  Normal_significance[i] <-  "*"  
  }
  if(Normal_pv[i]<0.05){
  Normal_significance[i] <-  "**"  
  }
  if(Normal_pv[i]<0.01){
  Normal_significance[i] <-  "***"  
  }
  }
  Normal_significance[is.na(Normal_significance)] <- ""

#maximum likelihood estimates of unconditional distribution functions
Table2 <- matrix(nrow = 6, ncol = 7)
colnames(Table2) <- c("mu","sigma","lambda","p","q","L","AIC")
rownames(Table2) <- c("SGT","SGED","GED","ST","T","Normal")

Table2[1,1] <- SGT_result$estimate[1]
Table2[1,2] <- SGT_result$estimate[2]
Table2[1,3] <- SGT_result$estimate[3]
Table2[1,4] <- SGT_result$estimate[4]
Table2[1,5] <- SGT_result$estimate[5]
Table2[1,6] <- SGT_result$maximum
Table2[1,7] <- SGT_AIC

Table2[2,1] <- SGED_result$estimate[1]
Table2[2,2] <- SGED_result$estimate[2]
Table2[2,3] <- SGED_result$estimate[4]
Table2[2,4] <- SGED_result$estimate[3]
Table2[2,5] <- Inf
Table2[2,6] <- SGED_result$loglik
Table2[2,7] <- SGT_AIC

Table2[3,1] <- GED_result$estimate[1]
Table2[3,2] <- GED_result$estimate[2]
Table2[3,3] <- 0
Table2[3,4] <- GED_result$estimate[3]
Table2[3,5] <- Inf 
Table2[3,6] <- GED_result$loglik
Table2[3,7] <- GED_AIC

Table2[4,1] <- ST_result$estimate[1]
Table2[4,2] <- ST_result$estimate[2]
Table2[4,3] <- ST_result$estimate[4]
Table2[4,4] <- ST_result$estimate[3]
Table2[4,5] <- 2
Table2[4,6] <- ST_result$loglik
Table2[4,7] <- ST_result$aic

Table2[5,1] <- T_result$estimate[1]
Table2[5,2] <- T_result$estimate[2]
Table2[5,3] <- 0 
Table2[5,4] <- T_result$estimate[3] 
Table2[5,5] <- 2
Table2[5,6] <- T_result$loglik
Table2[5,7] <- T_result$aic

Table2[6,1] <- Normal_mu
Table2[6,2] <- Normal_sigma
Table2[6,3] <- 0
Table2[6,4] <- Inf 
Table2[6,5] <- 2
Table2[6,6] <- Normal_result$loglik
Table2[6,7] <- Normal_result$aic

#adding SE
Table2_SE <- matrix(nrow = 12, ncol = 7)

Table2_SE <- as.data.frame(Table2_SE)
#coefficients
Table2_SE[1,] <- Table2[1,]
Table2_SE[3,] <- Table2[2,]
Table2_SE[5,] <- Table2[3,]
Table2_SE[7,] <- Table2[4,]
Table2_SE[9,] <- Table2[5,]
Table2_SE[11,] <- Table2[6,]


#fixing rownames
colnames(Table2_SE) <- c("mu","sigma","lambda","p","q","L","AIC")
rownames(Table2_SE) <- c(1,2,3,4,5,6,7,8,9,10,11,12)
tablenames <- c("SGT","","SGED","","GED","","ST","","T","","Normal","")
Table2_SE <- cbind(tablenames,Table2_SE)

Table2_SE[c(1,3,5,7,9,11),-1] <- round(Table2_SE[c(1,3,5,7,9,11),-1], 3)

#SEs (basic)
Table2_SE[2,2:6] <- paste0("(",round(SGT_result$std.error, 3),")",SGT_significance)
Table2_SE[4,2:6] <- paste0("(",round(SGED_result$sd, 3),")",SGED_significance)
Table2_SE[6,2:6] <- paste0("(",round(GED_result$sd, 3),")",GED_significance)
Table2_SE[8,2:4] <- paste0("(",round(ST_result$sd[-3],3),")",ST_significance[1:3])
Table2_SE[8,6] <- paste0("(",round(ST_result$sd[3],3),")", ST_significance[6])
Table2_SE[10,2:3] <- paste0("(",round(T_result$sd[-3],3),")",T_significance[1:2])
Table2_SE[10,6] <- paste0("(",round(T_result$sd[3],3),")",T_significance[6])
Table2_SE[12,2:3] <- paste0("(",round(Normal_result$sd, 3),")",Normal_significance)


#Remove SE for limiting cases
# Table2_SE[6,4] <- NA
# Table2_SE[c(4,6),6] <- NA

totalresults <- list(table = Table2_SE, results = list(SGT = SGT_sumResult,SGED = SGED_sumResult, GED = GED_sumResult, ST = ST_sumResult, T = T_sumResult, Norm =Normal_sumResult))
return(totalresults)
}

```

```{r MLE tables for different series, include=FALSE, eval=FALSE}

R_dotcom <- window(R, start = "1987-01-01", end = "2001-12-31")
R_GFC <- window(R, start = "2002-01-01", end = "2009-03-31")
R_covid <- window(R, start = "2009-03-31")
length(R_dotcom); length(R_GFC); length(R_covid)

MLE_Full <- DistMLE(R)
MLE_dotcom <- DistMLE(R_dotcom)
MLE_GFC <- DistMLE(R_GFC)
MLE_covid <- DistMLE(R_covid)
```

In table \@ref(tab:MLEtable) we can see the estimated parameters of the unconditional distribution functions. They are presented for the Skewed Generalized T-distribution (SGT) and limiting cases thereof previously discussed. Additionally, maximum likelihood score and the Aikake Information Criterion (AIC) is reported to compare goodness of fit of the different distributions. We find that the SGT-distribution has the highest maximum likelihood score of all. All other distributions have relatively similar likelihood scores, though slightly lower and are therefore not the optimal distributions. However, when considering AIC it is a tie between SGT and SGED. This provides some indication that we have a valid case to test the suitability of different SGED-GARCH VaR models as an alternative for the SGT-GARCH VaR models. While sacrificing some goodness of fit, the SGED distribution has the advantage of requiring one less parameter, which could possibly result in less errors due to misspecification and easier implementation.  For the SGT parameters the standard deviation and skewness are both significant at the 1% level. For the SGED parameters, the standard deviation and the skewness are both significant at respectively the 1% and 5% level. Both distributions are right-skewed. For both distributions the shape parameters are significant at the 1% level, though the $q$ parameter was not estimated as it is by design set to infinity due to the SGED being a limiting case of SGT.^[To check whether the relative ranking of distributions still holds in different periods, we have calculated the maximum likelihood score and AIC for three smaller periods: The period up to the dotcom collapse (1987-2001), up to the GFC (2002-2009) and  up to the present Covid-crash (2009-2021). There is no qualitative difference in relative ranking with these subsamples. Results are reported in the appendix.] 

Additionally, for every distribution fitted with MLE, plots are generated to compare the theoretical distribution with the observed returns. We see that except for the normal distribution which is quite off, the theoretical distributions are close to the actual data, except that they are too peaked. This problem is the least present for the SGT distribution. 

```{r Euro Stoxx,, echo=FALSE}
par(mfrow = c(3,2), mar = c(1,4,3,3))
Eurostoxx <- DistMLE(R)
table2 <- Eurostoxx$table
Eurostoxx$results$SGT
colnames(table2) <- c("", "$\\mu$","$\\sigma$","$\\lambda$","$\\kappa$","$\\nu$","$L$","AIC")  
```

```{r results='asis'}
kbl(Eurostoxx$table,caption = "Maximum likelihood estimates of unconditional distribution functions",
      label = 'MLEtable',
      booktabs = T,
      position = "h!",
      digits = 3,
      col.names = )%>%
  kable_classic(full_width = F)%>% 
  footnote(general = "Table contains parameter estimates for SGT-distribution and some of its limiting cases. The underlying data is the daily return series of the Eurostoxx 50 for the period between December 31. 1986 and April 27. 2021. Standard errors are reported between brackets. $L$ is the maximum log-likelihood value. *, ** and *** point out significance at 10%, 5% and 1% level.",threeparttable = T,footnote_as_chunk = F, escape=F, general_title = "")
```



## Results of GARCH with constant higher moments

<!--# Here comes our main part [FILIPPO] -> to do!  -->

```{r garchcode, echo=FALSE}
distributions <- c("norm", "std", "sstd", "ged", "sged")
Models.garch <- c("sGARCH", "eGARCH","fGARCH.AVGARCH","fGARCH.NAGARCH", "gjrGARCH", "fGARCH.TGARCH", "iGARCH", "EWMA")
Models.garch.clean <-  toupper(gsub("fGARCH.", "", Models.garch)) # we use this for tables

for(i in 1:length(Models.garch)){
assign(paste0("garchspec.",Models.garch[i]),vector(mode = "list", length = length(distributions)))
assign(paste0("garchfit.",Models.garch[i]),vector(mode = "list", length = length(distributions)))
assign(paste0("stdret.",Models.garch[i]),vector(mode = "list", length = length(distributions)))
} 

#.sGARCH--------------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.sGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "sGARCH", garchOrder = c(1,1), variance.targeting = F), 
                     distribution.model = distributions[i])
# Estimate the model
garchfit.sGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.sGARCH[[i]])
# Compute stdret using residuals()
stdret.sGARCH[[i]] <- residuals(garchfit.sGARCH[[i]], standardize = TRUE)
}

#.eGARCH-------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.eGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "eGARCH", variance.targeting = F), 
                     distribution.model = distributions[i])
# Estimate the model
garchfit.eGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.eGARCH[[i]])
# Compute stdret using residuals()
stdret.eGARCH[[i]] <- residuals(garchfit.eGARCH[[i]], standardize = TRUE)
}

#.fGARCH.NAGARCH------------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.fGARCH.NAGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "fGARCH", submodel = "NAGARCH", variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.fGARCH.NAGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.fGARCH.NAGARCH[[i]])
# Compute stdret using residuals()
stdret.fGARCH.NAGARCH[[i]] <- residuals(garchfit.fGARCH.NAGARCH[[i]], standardize = TRUE)
}

#.fGARCH.AVGARCH------------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.fGARCH.AVGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "fGARCH", submodel = "AVGARCH", variance.targeting = F),
                     distribution.model = distributions[i])
# Estimate the model
garchfit.fGARCH.AVGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.fGARCH.AVGARCH[[i]])
# Compute stdret using residuals()
stdret.fGARCH.AVGARCH[[i]] <- residuals(garchfit.fGARCH.AVGARCH[[i]], standardize = TRUE)
}

#.gjrGARCH------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.gjrGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "gjrGARCH", variance.targeting = F), 
                     distribution.model = distributions[i])
# Estimate the model
garchfit.gjrGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.gjrGARCH[[i]])
# Compute stdret using residuals()
stdret.gjrGARCH[[i]] <- residuals(garchfit.gjrGARCH[[i]], standardize = TRUE)
}

#fGARCH.TGARCH-------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.fGARCH.TGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "fGARCH", submodel = "TGARCH", variance.targeting = F), 
                     distribution.model = distributions[i])
# Estimate the model
garchfit.fGARCH.TGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.fGARCH.TGARCH[[i]])
# Compute stdret using residuals()
stdret.fGARCH.TGARCH[[i]] <- residuals(garchfit.fGARCH.TGARCH[[i]], standardize = TRUE)
}

#.iGARCH--------------------
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.iGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "iGARCH", variance.targeting = F), 
                     distribution.model = distributions[i])
# Estimate the model
garchfit.iGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.iGARCH[[i]])
# Compute stdret using residuals()
stdret.iGARCH[[i]] <- residuals(garchfit.iGARCH[[i]], standardize = TRUE)
}

#.csGARCH-----------------
# for(i in 1:length(distributions)){
# # Specify a GARCH model with constant mean
# garchspec.csGARCH[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
#                      variance.model = list(model = "csGARCH", variance.targeting = F),
#                      distribution.model = distributions[i])
# # Estimate the model
# garchfit.csGARCH[[i]] <- ugarchfit(data = R, spec = garchspec.csGARCH[[i]])
# # Compute stdret using residuals()
# stdret.csGARCH[[i]] <- residuals(garchfit.csGARCH[[i]], standardize = TRUE)
# }


# we need EWMA
for(i in 1:length(distributions)){
# Specify a GARCH model with constant mean
garchspec.EWMA[[i]] <- ugarchspec(mean.model = list(armaOrder = c(1,0)),
                     variance.model = list(model = "iGARCH", variance.targeting = F),
                     distribution.model = distributions[i], fixed.pars = list(omega=0))
# Estimate the model
garchfit.EWMA[[i]] <- ugarchfit(data = R, spec = garchspec.EWMA[[i]])
# Compute stdret using residuals()
stdret.EWMA[[i]] <- residuals(garchfit.EWMA[[i]], standardize = TRUE)
}


#  make the histogram
# 
# chart.Histogram(stdret.iGARCH[[1]], methods = c("add.normal","add.density" ),
#                 colorset = c("gray","red","blue"))
```


<!-- What do we do, do we do 6 tables for all the distributions?  -->
```{r table3prep, eval=FALSE}

table.3.function <- function(GARCHfit.object = garchfit.eGARCH){
#Making objects to fill  
list.table.3.tmp <- vector(mode = "list", length = length(distributions)*2)
list.table.3 <- vector(mode = "list", length = length(distributions))
names(list.table.3) <- distributions
ref.distr <- seq(from = 1, to = length(distributions)*2, by = 2)
#Retriving all the data from the original lists
for(i in 1:length(distributions)){
    list.table.3.tmp[[ref.distr[i]]] <- GARCHfit.object[[i]]@fit$coef
    list.table.3.tmp[[ref.distr[i]+1]] <- GARCHfit.object[[i]]@fit$tval
}
#From list of vectors of different lengths to list of matrixes with empty spaces filled with NAs
for(i in 1:length(distributions)){
  #length(list.table.3.tmp[[ref.distr[i]+1]]) <- length(list.table.3.tmp[[ref.distr[i]]])
  list.table.3[[i]] <- cbind(list.table.3.tmp[[ref.distr[i]]], list.table.3.tmp[[ref.distr[i]+1]][match(names(list.table.3.tmp[[ref.distr[i]]]), names(list.table.3.tmp[[ref.distr[i]+1]]))])
}
#Function to rearrange the list from a list of matrices to list of vectors
list.restructure <- function(object = list.table.3){
  len.table <- length(object)
  len.inside.list <- rep(NA, len.table)
  for(i in 1:len.table){len.inside.list[i] <- nrow(object[[i]])}
  adj.list <- vector(mode = "list", length = len.table)
  ref.list <- vector(mode = "list", length = len.table)
  names.list <- vector(mode = "list", length = len.table)
  for(i in 1:len.table){ref.list[[i]] <- seq(from = 1, to = len.inside.list[i]*2, by = 2)}
  for(i in 1:len.table){adj.list[[i]] <- names.list[[i]] <- rep(NA, len.inside.list[i]*2)}
  for(i in 1:len.table){
      adj.list[[i]][ref.list[[i]]] <- round(object[[i]][,1],3)
      adj.list[[i]][ref.list[[i]]+1] <- paste0("(", round(object[[i]][,2],3),")")
  }
  for(i in 1:len.table){
    names.list[[i]][ref.list[[i]]] <- rownames(object[[i]])
    #names.list[[i]][ref.list[[i]]+1] <- paste0("p-val ",rownames(object[[i]]))
    names.list[[i]][ref.list[[i]]+1] <- ""
    }
  names(adj.list) <- distributions
  for(i in 1:len.table){names(adj.list[[i]]) <- names.list[[i]]}
  return(adj.list)
}
#Unlisting and removing NAs
adj.list  <- list.restructure(object = list.table.3)
table.3.matrix <- matrix(unlist(lapply(adj.list, `length<-`, max(lengths(adj.list)))), 
                                 ncol = length(distributions),nrow = max(lengths(adj.list)), byrow = F)
colnames(table.3.matrix) <- names(adj.list)
table.3.matrix[is.na(table.3.matrix)] <- ""
table.3.matrix[table.3.matrix=="(NA)"] <- ""

#Adjustments for std & ged distributions
table.3.matrix[c(length(table.3.matrix[,2])-1,length(table.3.matrix[,2])),2] <- tail(table.3.matrix[table.3.matrix[,2]!="",2],2)
table.3.matrix[c(length(table.3.matrix[,2])-3,length(table.3.matrix[,2])-2),2] <- ""
table.3.matrix[c(length(table.3.matrix[,4])-1,length(table.3.matrix[,4])),4] <- tail(table.3.matrix[table.3.matrix[,4]!="",4],2)
table.3.matrix[c(length(table.3.matrix[,4])-3,length(table.3.matrix[,4])-2),4] <- ""
#Log-Likelyhoods
LLH <- rep(NA, length(distributions))
for(i in 1:length(distributions)){LLH[i] <- GARCHfit.object[[i]]@fit$LLH}
table.3.matrix <- rbind(table.3.matrix, round(LLH,3))
table.3.matrix <- cbind(c(names(adj.list[[3]]),"LLH"), table.3.matrix)
table.3.matrix <- as.data.frame(table.3.matrix, row.names = NULL)

return(table.3.matrix)
}

#RESULTS

Table.3.iGARCH <- table.3.function(GARCHfit.object = garchfit.iGARCH)
Table.3.eGARCH <- table.3.function(GARCHfit.object = garchfit.eGARCH)
Table.3.gjrGARCH <- table.3.function(GARCHfit.object = garchfit.gjrGARCH)
Table.3.sGARCH <- table.3.function(GARCHfit.object = garchfit.sGARCH)
Table.3.EWMA <- table.3.function(GARCHfit.object = garchfit.EWMA)
Table.3.fGARCH.AVGARCH <- table.3.function(GARCHfit.object = garchfit.fGARCH.AVGARCH)
Table.3.fGARCH.NAGARCH <- table.3.function(GARCHfit.object = garchfit.fGARCH.NAGARCH)
Table.3.fGARCH.TGARCH <- table.3.function(GARCHfit.object = garchfit.fGARCH.TGARCH)

```

```{r table4prep, eval=FALSE}
print("iGARCH")
garchfit.iGARCH[[1]]@fit$coef
garchfit.iGARCH[[1]]@fit$se.coef
```

```{r table5prep, eval=FALSE}
print("EWMA")
garchfit.EWMA[[1]]@fit$coef
c(garchfit.EWMA[[1]]@fit$se.coef[1:2],NA,garchfit.EWMA[[1]]@fit$se.coef[3], NA)
```

```{r table7prep, eval=FALSE}
print("eGARCH")
garchfit.eGARCH[[1]]@fit$coef
garchfit.eGARCH[[1]]@fit$se.coef
```

```{r table6prep, eval=FALSE}
print("gjrGARCH")
garchfit.gjrGARCH[[1]]@fit$coef
garchfit.gjrGARCH[[1]]@fit$se.coef
```

```{r table8prep, eval=FALSE}
print("NAGARCH")
garchfit.fGARCH.NAGARCH[[1]]@fit$coef
garchfit.fGARCH.NAGARCH[[1]]@fit$se.coef
```

```{r table9prep, eval=FALSE}
print("TGARCH")
garchfit.fGARCH.TGARCH[[1]]@fit$coef
garchfit.fGARCH.TGARCH[[1]]@fit$se.coef
```

```{r table10prep, eval=FALSE}
garchfit.fGARCH.AVGARCH[[1]]@fit$coef
garchfit.fGARCH.AVGARCH[[1]]@fit$se.coef
```
<!-- Here comes the description -->

```{r aictable, echo=F, results='asis'}

aic_sGARCH <- vector(length=length(distributions)) 
for (i in 1:length(distributions)) {
  aic_sGARCH[i] = infocriteria(garchfit.sGARCH[[i]])[1]
} 

aic_iGARCH <- vector(length=length(distributions)) 
for (i in 1:length(distributions)) {
  aic_iGARCH[i] = infocriteria(garchfit.iGARCH[[i]])[1]
} 

aic_EWMA <- vector(length=length(distributions)) 
for (i in 1:length(distributions)) {
  aic_EWMA[i] = infocriteria(garchfit.EWMA[[i]])[1]
} 

aic_eGARCH <- vector(length=length(distributions)) 
for (i in 1:length(distributions)) {
  aic_eGARCH[i] = infocriteria(garchfit.eGARCH[[i]])[1]
} 

aic_gjrGARCH <- vector(length=length(distributions)) 
for (i in 1:length(distributions)) {
  aic_gjrGARCH[i] = infocriteria(garchfit.gjrGARCH[[i]])[1]
} 

aic_naGARCH <- vector(length=length(distributions)) 
for (i in 1:length(distributions)) {
  aic_naGARCH[i] = infocriteria(garchfit.fGARCH.NAGARCH[[i]])[1]
} 

aic_tGARCH <- vector(length=length(distributions)) 
for (i in 1:length(distributions)) {
  aic_tGARCH[i] = infocriteria(garchfit.fGARCH.TGARCH[[i]])[1]
} 

aic_avgarch <- vector(length=length(distributions)) 
for (i in 1:length(distributions)) {
  aic_avgarch[i] = infocriteria(garchfit.fGARCH.AVGARCH[[i]])[1]
} 

aics <- matrix(ncol=length(Models.garch), nrow = length(distributions))
rownames(aics) <- distributions
colnames(aics) <- Models.garch.clean[c(1,7,8,2,5,4,6,3)]
aics[,1] <- aic_sGARCH
aics[,2] <- aic_iGARCH
aics[,3] <- aic_EWMA
aics[,4] <- aic_eGARCH
aics[,5] <- aic_gjrGARCH
aics[,6] <- aic_naGARCH
aics[,7] <- aic_tGARCH
aics[,8] <- aic_avgarch

tableAIC <- as.data.frame(round(aics,4))

# cf <-  condformat(tableAIC) %>%
#   rule_fill_discrete(SGARCH,expression =SGARCH==min(SGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(IGARCH,expression =IGARCH==min(IGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(EWMA,expression =EWMA==min(EWMA), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(EGARCH,expression =EGARCH==min(EGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(GJRGARCH,expression =GJRGARCH==min(GJRGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(NAGARCH,expression =NAGARCH==min(NAGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen"))  %>%
#   rule_fill_discrete(TGARCH,expression =TGARCH==min(TGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) %>%
#   rule_fill_discrete(AVGARCH,expression =AVGARCH==min(AVGARCH), colours = c("FALSE" = "white", "TRUE" = "lightgreen")) 
aics %>% kbl(caption = "Model selection according to AIC","latex",
      label = 'aicTable',
      booktabs = T,
      position = "h!",
      digits = 3 )%>%
  kable_classic(full_width = F)%>% 
  footnote(general = "Notes",number="This table shows the AIC value for the respective model",threeparttable = T,footnote_as_chunk = F, escape=F, general_title = "") 
```


## Results of GARCH with time-varying higher moments

```{r acdcode, eval=FALSE}
require(racd)
require(rugarch)
require(parallel)
require(xts)
# ACD specification
sGARCH_ACDspec = acdspec(mean.model = list(armaOrder = c(1, 0)), variance.model = list(variance.targeting = TRUE),
distribution.model = list(model = 'jsu', skewOrder = c(1, 1, 1), shapeOrder = c(1,1,1), skewmodel = 'quad', shapemodel = 'pwl'))

# sGARCH
cl = makePSOCKcluster(10)
fit = acdfit(sGARCH_ACDspec, as.data.frame(R), solver = 'msoptim', solver.control = list(restarts = 10),cluster = cl) #very long process: starts from different starting values to find an optimum
```

```{r figureACDmoments, fig.cap = "Dynamics of the ACD model", fig.align='center', fig.subcap="This figure plots the conditional mean, the conditional volatility. The implied conditional time varying skewwness and excess kurtosis for the Euro Stoxx 50 series.", eval=FALSE}
# par(mfrow = c(2, 2), mai = c(0.75, 0.75, 0.3, 0.3))
# cm <- plot.zoo(xts(fit@model$modeldata$data, fit@model$modeldata$index), auto.grid = FALSE,minor.ticks = FALSE, main = 'Conditional Mean',yaxis.right = F, col = 'steelblue')
# cm <- lines(fitted(fit), col = 2)
# cm
# cs <- plot(xts(abs(fit@model$modeldata$data),fit@model$modeldata$index), auto.grid = FALSE,
# minor.ticks = FALSE, main = 'Conditional Sigma', yaxis.right = F,col = 'grey')
# cs <- lines(sigma(fit), col = 'steelblue')
# cs
# plot(racd::skewness(fit), col = 'steelblue',yaxis.right = F, main = 'Conditional Skewness')
# plot(racd::kurtosis(fit), col = 'steelblue', yaxis.right = F,main = 'Conditional Excess Kurtosis')

# pnl <- function(fitted(fit),xts(fit@model$modeldata$data, fit@model$modeldata$index), ...) {
#   panel.number <- parent.frame()$panel.number
# 	if (panel.number == 1) lines(fitted(fit), xts(fit@model$modeldata$data, fit@model$modeldata$index),col = "red")
# 	lines(fitted(fit),xts(fit@model$modeldata$data, fit@model$modeldata$index), col = "red")
# }
# plot(xts(fit@model$modeldata$data, fit@model$modeldata$index), auto.grid = T,minor.ticks = FALSE,major.ticks=T, yaxis.right = F, main = 'Conditional Mean', col = 'steelblue', xlab = "", screens = 1, ylab="") #panel = pnl
# # lines(fitted(fit), col = 2) + grid()
# 
# plot(xts(fit@model$modeldata$data, fit@model$modeldata$index), auto.grid = T,minor.ticks = FALSE,major.ticks=T, yaxis.right = F, main = 'Conditional Mean', col = 'steelblue', xlab = "", screens = 1, ylab="", )
```
